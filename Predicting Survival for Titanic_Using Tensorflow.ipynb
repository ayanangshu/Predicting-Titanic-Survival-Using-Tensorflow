{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('titanic_data - Copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Pclass on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "print(df[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we took a mean, this data represents that Pclass=1 survival rate is 62.96%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Sex on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex is a categorical attribute having values as male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of Sex attribute on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "print(df[['Sex','Survived']].groupby(['Sex'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows female survival rate is more than the male counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing impact of Siblings on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SibSp is a numerical attribute represents siblings/spouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SibSp  Survived\n",
      "0      0  0.345395\n",
      "1      1  0.535885\n",
      "2      2  0.464286\n",
      "3      3  0.250000\n",
      "4      4  0.166667\n",
      "5      5  0.000000\n",
      "6      8  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"SibSp\",\"Survived\"]].groupby(['SibSp'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Impact of Parents on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch is also a numerical attribute which represents the children/parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parch  Survived\n",
      "0      0  0.343658\n",
      "1      1  0.550847\n",
      "2      2  0.500000\n",
      "3      3  0.600000\n",
      "4      4  0.000000\n",
      "5      5  0.200000\n",
      "6      6  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"Parch\",\"Survived\"]].groupby(['Parch'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the impact of SibSp & Parch,lets create a new attribute called Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "df['FamilySize']=df['SibSp']+df['Parch']+1\n",
    "\n",
    "print(df[['FamilySize','Survived']].groupby(['FamilySize'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family Size seems to have a good effect on survival chance. Let's see what is the effect of being alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n"
     ]
    }
   ],
   "source": [
    "df['IsAlone']=0\n",
    "df.loc[df['FamilySize']==1,'IsAlone']=1\n",
    "print(df[['IsAlone','Survived']].groupby(['IsAlone'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Age Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CategoricalAge  Survived\n",
      "0  (-0.08, 16.0]  0.532110\n",
      "1   (16.0, 32.0]  0.364269\n",
      "2   (32.0, 48.0]  0.354244\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayana\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "age_avg=df['Age'].mean()\n",
    "age_std=df['Age'].std()\n",
    "age_null_count=df['Age'].isnull().sum()\n",
    "age_null_random_list=np.random.randint(age_avg-age_std,age_avg+age_std,size=age_null_count)\n",
    "df['Age'][np.isnan(df['Age'])]=age_null_random_list\n",
    "df['Age']=df['Age'].astype(int)\n",
    "\n",
    "df['CategoricalAge']=pd.cut(df['Age'],5)\n",
    "print(df[['CategoricalAge','Survived']].groupby(['CategoricalAge'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>CategoricalAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "5            6       3                                   Moran, Mr. James   \n",
       "6            7       1                            McCarthy, Mr. Timothy J   \n",
       "7            8       3                     Palsson, Master. Gosta Leonard   \n",
       "8            9       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9           10       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex  Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male   22      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female   38      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female   26      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female   35      1      0            113803  53.1000  C123        S   \n",
       "4    male   35      0      0            373450   8.0500   NaN        S   \n",
       "5    male   34      0      0            330877   8.4583   NaN        Q   \n",
       "6    male   54      0      0             17463  51.8625   E46        S   \n",
       "7    male    2      3      1            349909  21.0750   NaN        S   \n",
       "8  female   27      0      2            347742  11.1333   NaN        S   \n",
       "9  female   14      1      0            237736  30.0708   NaN        C   \n",
       "\n",
       "   Survived  FamilySize  IsAlone CategoricalAge  \n",
       "0         0           2        0   (16.0, 32.0]  \n",
       "1         1           2        0   (32.0, 48.0]  \n",
       "2         1           1        1   (16.0, 32.0]  \n",
       "3         1           2        0   (32.0, 48.0]  \n",
       "4         0           1        1   (32.0, 48.0]  \n",
       "5         0           1        1   (32.0, 48.0]  \n",
       "6         0           1        1   (48.0, 64.0]  \n",
       "7         0           5        0  (-0.08, 16.0]  \n",
       "8         1           3        0   (16.0, 32.0]  \n",
       "9         1           2        0  (-0.08, 16.0]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Sex into numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex']=df['Sex'].fillna(0)\n",
    "df['Sex']=df['Sex'].map({'female':0,'male':1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked attribute is having missing values, best way to fill this would be by most occured value. In this dataset the most\n",
    "# occured value for embarked attribute is 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n"
     ]
    }
   ],
   "source": [
    "# Fill missing embarked value with mode\n",
    "df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "print(df[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked']=df['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Fare']<=7.91,'Fare']=0\n",
    "df.loc[(df['Fare']>7.91)&(df['Fare']<=14.454),'Fare']=1\n",
    "df.loc[(df['Fare']>14.454)&(df['Fare']<=31),'Fare']=2\n",
    "df.loc[df['Fare']>31,'Fare']=3\n",
    "df['Fare']=df['Fare'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age']<=16,'Age']=0\n",
    "df.loc[(df['Age']>16)&(df['Age']<=32),'Age']=1\n",
    "df.loc[(df['Age']>32)&(df['Age']<=48),'Age']=2\n",
    "df.loc[(df['Age']>48)&(df['Age']<=64),'Age']=3\n",
    "df.loc[(df['Age']>64),'Age']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df=pd.read_csv('titanic_data - Copy.csv')\n",
    "    X=df[df.columns[0:11]].values\n",
    "    y=df[df.columns[11]]\n",
    "    \n",
    "    #Encode the dependent variable\n",
    "    encoder=LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y=encoder.transform(y)\n",
    "    Y=one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encode=np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels]=1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>CategoricalAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex  Age  SibSp  Parch            Ticket  Fare Cabin  Embarked  Survived  \\\n",
       "0    1    0      1      0         A/5 21171   0.0   NaN         0         0   \n",
       "1    0    0      1      0          PC 17599   3.0   C85         1         1   \n",
       "2    0    0      0      0  STON/O2. 3101282   1.0   NaN         0         1   \n",
       "3    0    0      1      0            113803   3.0  C123         0         1   \n",
       "4    1    0      0      0            373450   1.0   NaN         0         0   \n",
       "\n",
       "   FamilySize  IsAlone CategoricalAge  \n",
       "0           2        0   (16.0, 32.0]  \n",
       "1           2        0   (32.0, 48.0]  \n",
       "2           1        1   (16.0, 32.0]  \n",
       "3           2        0   (32.0, 48.0]  \n",
       "4           1        1   (32.0, 48.0]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove =['CategoricalAge','Ticket','Cabin','Name']\n",
    "df1=df[df.columns.difference(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Embarked  FamilySize  Fare  IsAlone  Parch  PassengerId  Pclass  \\\n",
      "0      0         0           2   0.0        0      0            1       3   \n",
      "1      0         1           2   3.0        0      0            2       1   \n",
      "2      0         0           1   1.0        1      0            3       3   \n",
      "3      0         0           2   3.0        0      0            4       1   \n",
      "4      0         0           1   1.0        1      0            5       3   \n",
      "5      0         2           1   1.0        1      0            6       3   \n",
      "6      0         0           1   3.0        1      0            7       1   \n",
      "7      0         0           5   2.0        0      1            8       3   \n",
      "8      0         0           3   1.0        0      2            9       3   \n",
      "9      0         1           2   2.0        0      0           10       2   \n",
      "10     0         0           3   2.0        0      1           11       3   \n",
      "11     0         0           1   2.0        1      0           12       1   \n",
      "12     0         0           1   1.0        1      0           13       3   \n",
      "13     0         0           7   3.0        0      5           14       3   \n",
      "14     0         0           1   0.0        1      0           15       3   \n",
      "15     0         0           1   2.0        1      0           16       2   \n",
      "16     0         2           6   2.0        0      1           17       3   \n",
      "17     0         0           1   1.0        1      0           18       2   \n",
      "18     0         0           2   2.0        0      0           19       3   \n",
      "19     0         1           1   0.0        1      0           20       3   \n",
      "20     0         0           1   2.0        1      0           21       2   \n",
      "21     0         0           1   1.0        1      0           22       2   \n",
      "22     0         2           1   1.0        1      0           23       3   \n",
      "23     0         0           1   3.0        1      0           24       1   \n",
      "24     0         0           5   2.0        0      1           25       3   \n",
      "25     0         0           7   3.0        0      5           26       3   \n",
      "26     0         1           1   0.0        1      0           27       3   \n",
      "27     0         0           6   3.0        0      2           28       1   \n",
      "28     0         2           1   0.0        1      0           29       3   \n",
      "29     0         0           1   0.0        1      0           30       3   \n",
      "..   ...       ...         ...   ...      ...    ...          ...     ...   \n",
      "861    0         0           2   1.0        0      0          862       2   \n",
      "862    0         0           1   2.0        1      0          863       1   \n",
      "863    0         0          11   3.0        0      2          864       3   \n",
      "864    0         0           1   1.0        1      0          865       2   \n",
      "865    0         0           1   1.0        1      0          866       2   \n",
      "866    0         1           2   1.0        0      0          867       2   \n",
      "867    0         0           1   3.0        1      0          868       1   \n",
      "868    0         0           1   1.0        1      0          869       3   \n",
      "869    0         0           3   1.0        0      1          870       3   \n",
      "870    0         0           1   0.0        1      0          871       3   \n",
      "871    0         0           3   3.0        0      1          872       1   \n",
      "872    0         0           1   0.0        1      0          873       1   \n",
      "873    0         0           1   1.0        1      0          874       3   \n",
      "874    0         1           2   2.0        0      0          875       2   \n",
      "875    0         1           1   0.0        1      0          876       3   \n",
      "876    0         0           1   1.0        1      0          877       3   \n",
      "877    0         0           1   0.0        1      0          878       3   \n",
      "878    0         0           1   0.0        1      0          879       3   \n",
      "879    0         1           2   3.0        0      1          880       1   \n",
      "880    0         0           2   2.0        0      1          881       2   \n",
      "881    0         0           1   0.0        1      0          882       3   \n",
      "882    0         0           1   1.0        1      0          883       3   \n",
      "883    0         0           1   1.0        1      0          884       2   \n",
      "884    0         0           1   0.0        1      0          885       3   \n",
      "885    0         2           6   2.0        0      5          886       3   \n",
      "886    0         0           1   1.0        1      0          887       2   \n",
      "887    0         0           1   2.0        1      0          888       1   \n",
      "888    0         0           4   2.0        0      2          889       3   \n",
      "889    0         1           1   2.0        1      0          890       1   \n",
      "890    0         2           1   0.0        1      0          891       3   \n",
      "\n",
      "     Sex  SibSp  Survived  \n",
      "0      1      1         0  \n",
      "1      0      1         1  \n",
      "2      0      0         1  \n",
      "3      0      1         1  \n",
      "4      1      0         0  \n",
      "5      1      0         0  \n",
      "6      1      0         0  \n",
      "7      1      3         0  \n",
      "8      0      0         1  \n",
      "9      0      1         1  \n",
      "10     0      1         1  \n",
      "11     0      0         1  \n",
      "12     1      0         0  \n",
      "13     1      1         0  \n",
      "14     0      0         0  \n",
      "15     0      0         1  \n",
      "16     1      4         0  \n",
      "17     1      0         1  \n",
      "18     0      1         0  \n",
      "19     0      0         1  \n",
      "20     1      0         0  \n",
      "21     1      0         1  \n",
      "22     0      0         1  \n",
      "23     1      0         1  \n",
      "24     0      3         0  \n",
      "25     0      1         1  \n",
      "26     1      0         0  \n",
      "27     1      3         0  \n",
      "28     0      0         1  \n",
      "29     1      0         0  \n",
      "..   ...    ...       ...  \n",
      "861    1      1         0  \n",
      "862    0      0         1  \n",
      "863    0      8         0  \n",
      "864    1      0         0  \n",
      "865    0      0         1  \n",
      "866    0      1         1  \n",
      "867    1      0         0  \n",
      "868    1      0         0  \n",
      "869    1      1         1  \n",
      "870    1      0         0  \n",
      "871    0      1         1  \n",
      "872    1      0         0  \n",
      "873    1      0         0  \n",
      "874    0      1         1  \n",
      "875    0      0         1  \n",
      "876    1      0         0  \n",
      "877    1      0         0  \n",
      "878    1      0         0  \n",
      "879    0      0         1  \n",
      "880    0      0         1  \n",
      "881    1      0         0  \n",
      "882    0      0         0  \n",
      "883    1      0         0  \n",
      "884    1      0         0  \n",
      "885    0      0         0  \n",
      "886    1      0         0  \n",
      "887    0      0         1  \n",
      "888    0      1         0  \n",
      "889    1      0         1  \n",
      "890    1      0         0  \n",
      "\n",
      "[891 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1[df1['Age']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Embarked  Survived  \\\n",
       "0              1       3    1    0      1      0   0.0         0         0   \n",
       "1              2       1    0    0      1      0   3.0         1         1   \n",
       "2              3       3    0    0      0      0   1.0         0         1   \n",
       "3              4       1    0    0      1      0   3.0         0         1   \n",
       "4              5       3    1    0      0      0   1.0         0         0   \n",
       "5              6       3    1    0      0      0   1.0         2         0   \n",
       "6              7       1    1    0      0      0   3.0         0         0   \n",
       "7              8       3    1    0      3      1   2.0         0         0   \n",
       "8              9       3    0    0      0      2   1.0         0         1   \n",
       "9             10       2    0    0      1      0   2.0         1         1   \n",
       "10            11       3    0    0      1      1   2.0         0         1   \n",
       "11            12       1    0    0      0      0   2.0         0         1   \n",
       "12            13       3    1    0      0      0   1.0         0         0   \n",
       "13            14       3    1    0      1      5   3.0         0         0   \n",
       "14            15       3    0    0      0      0   0.0         0         0   \n",
       "15            16       2    0    0      0      0   2.0         0         1   \n",
       "16            17       3    1    0      4      1   2.0         2         0   \n",
       "17            18       2    1    0      0      0   1.0         0         1   \n",
       "18            19       3    0    0      1      0   2.0         0         0   \n",
       "19            20       3    0    0      0      0   0.0         1         1   \n",
       "20            21       2    1    0      0      0   2.0         0         0   \n",
       "21            22       2    1    0      0      0   1.0         0         1   \n",
       "22            23       3    0    0      0      0   1.0         2         1   \n",
       "23            24       1    1    0      0      0   3.0         0         1   \n",
       "24            25       3    0    0      3      1   2.0         0         0   \n",
       "25            26       3    0    0      1      5   3.0         0         1   \n",
       "26            27       3    1    0      0      0   0.0         1         0   \n",
       "27            28       1    1    0      3      2   3.0         0         0   \n",
       "28            29       3    0    0      0      0   0.0         2         1   \n",
       "29            30       3    1    0      0      0   0.0         0         0   \n",
       "..           ...     ...  ...  ...    ...    ...   ...       ...       ...   \n",
       "861          862       2    1    0      1      0   1.0         0         0   \n",
       "862          863       1    0    0      0      0   2.0         0         1   \n",
       "863          864       3    0    0      8      2   3.0         0         0   \n",
       "864          865       2    1    0      0      0   1.0         0         0   \n",
       "865          866       2    0    0      0      0   1.0         0         1   \n",
       "866          867       2    0    0      1      0   1.0         1         1   \n",
       "867          868       1    1    0      0      0   3.0         0         0   \n",
       "868          869       3    1    0      0      0   1.0         0         0   \n",
       "869          870       3    1    0      1      1   1.0         0         1   \n",
       "870          871       3    1    0      0      0   0.0         0         0   \n",
       "871          872       1    0    0      1      1   3.0         0         1   \n",
       "872          873       1    1    0      0      0   0.0         0         0   \n",
       "873          874       3    1    0      0      0   1.0         0         0   \n",
       "874          875       2    0    0      1      0   2.0         1         1   \n",
       "875          876       3    0    0      0      0   0.0         1         1   \n",
       "876          877       3    1    0      0      0   1.0         0         0   \n",
       "877          878       3    1    0      0      0   0.0         0         0   \n",
       "878          879       3    1    0      0      0   0.0         0         0   \n",
       "879          880       1    0    0      0      1   3.0         1         1   \n",
       "880          881       2    0    0      0      1   2.0         0         1   \n",
       "881          882       3    1    0      0      0   0.0         0         0   \n",
       "882          883       3    0    0      0      0   1.0         0         0   \n",
       "883          884       2    1    0      0      0   1.0         0         0   \n",
       "884          885       3    1    0      0      0   0.0         0         0   \n",
       "885          886       3    0    0      0      5   2.0         2         0   \n",
       "886          887       2    1    0      0      0   1.0         0         0   \n",
       "887          888       1    0    0      0      0   2.0         0         1   \n",
       "888          889       3    0    0      1      2   2.0         0         0   \n",
       "889          890       1    1    0      0      0   2.0         1         1   \n",
       "890          891       3    1    0      0      0   0.0         2         0   \n",
       "\n",
       "     FamilySize  IsAlone  \n",
       "0             2        0  \n",
       "1             2        0  \n",
       "2             1        1  \n",
       "3             2        0  \n",
       "4             1        1  \n",
       "5             1        1  \n",
       "6             1        1  \n",
       "7             5        0  \n",
       "8             3        0  \n",
       "9             2        0  \n",
       "10            3        0  \n",
       "11            1        1  \n",
       "12            1        1  \n",
       "13            7        0  \n",
       "14            1        1  \n",
       "15            1        1  \n",
       "16            6        0  \n",
       "17            1        1  \n",
       "18            2        0  \n",
       "19            1        1  \n",
       "20            1        1  \n",
       "21            1        1  \n",
       "22            1        1  \n",
       "23            1        1  \n",
       "24            5        0  \n",
       "25            7        0  \n",
       "26            1        1  \n",
       "27            6        0  \n",
       "28            1        1  \n",
       "29            1        1  \n",
       "..          ...      ...  \n",
       "861           2        0  \n",
       "862           1        1  \n",
       "863          11        0  \n",
       "864           1        1  \n",
       "865           1        1  \n",
       "866           2        0  \n",
       "867           1        1  \n",
       "868           1        1  \n",
       "869           3        0  \n",
       "870           1        1  \n",
       "871           3        0  \n",
       "872           1        1  \n",
       "873           1        1  \n",
       "874           2        0  \n",
       "875           1        1  \n",
       "876           1        1  \n",
       "877           1        1  \n",
       "878           1        1  \n",
       "879           2        0  \n",
       "880           2        0  \n",
       "881           1        1  \n",
       "882           1        1  \n",
       "883           1        1  \n",
       "884           1        1  \n",
       "885           6        0  \n",
       "886           1        1  \n",
       "887           1        1  \n",
       "888           4        0  \n",
       "889           1        1  \n",
       "890           1        1  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('titanic_data - Copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   Survived  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Survived\n",
      "0    0.42  1.000000\n",
      "1    0.67  1.000000\n",
      "2    0.75  1.000000\n",
      "3    0.83  1.000000\n",
      "4    0.92  1.000000\n",
      "5    1.00  0.714286\n",
      "6    2.00  0.300000\n",
      "7    3.00  0.833333\n",
      "8    4.00  0.700000\n",
      "9    5.00  1.000000\n",
      "10   6.00  0.666667\n",
      "11   7.00  0.333333\n",
      "12   8.00  0.500000\n",
      "13   9.00  0.250000\n",
      "14  10.00  0.000000\n",
      "15  11.00  0.250000\n",
      "16  12.00  1.000000\n",
      "17  13.00  1.000000\n",
      "18  14.00  0.500000\n",
      "19  14.50  0.000000\n",
      "20  15.00  0.800000\n",
      "21  16.00  0.352941\n",
      "22  17.00  0.461538\n",
      "23  18.00  0.346154\n",
      "24  19.00  0.360000\n",
      "25  20.00  0.200000\n",
      "26  20.50  0.000000\n",
      "27  21.00  0.208333\n",
      "28  22.00  0.407407\n",
      "29  23.00  0.333333\n",
      "..    ...       ...\n",
      "58  44.00  0.333333\n",
      "59  45.00  0.416667\n",
      "60  45.50  0.000000\n",
      "61  46.00  0.000000\n",
      "62  47.00  0.111111\n",
      "63  48.00  0.666667\n",
      "64  49.00  0.666667\n",
      "65  50.00  0.500000\n",
      "66  51.00  0.285714\n",
      "67  52.00  0.500000\n",
      "68  53.00  1.000000\n",
      "69  54.00  0.375000\n",
      "70  55.00  0.500000\n",
      "71  55.50  0.000000\n",
      "72  56.00  0.500000\n",
      "73  57.00  0.000000\n",
      "74  58.00  0.600000\n",
      "75  59.00  0.000000\n",
      "76  60.00  0.500000\n",
      "77  61.00  0.000000\n",
      "78  62.00  0.500000\n",
      "79  63.00  1.000000\n",
      "80  64.00  0.000000\n",
      "81  65.00  0.000000\n",
      "82  66.00  0.000000\n",
      "83  70.00  0.000000\n",
      "84  70.50  0.000000\n",
      "85  71.00  0.000000\n",
      "86  74.00  0.000000\n",
      "87  80.00  1.000000\n",
      "\n",
      "[88 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2[['Age','Survived']].groupby(['Age'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg=df2['Age'].mean()\n",
    "age_std=df2['Age'].std()\n",
    "age_null_count=df2['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_null_random_list=np.random.randint(age_avg-age_std,age_avg+age_std,size=age_null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayana\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df2['Age'][np.isnan(df2['Age'])]=age_null_random_list\n",
    "df2['Age']=df2['Age'].astype(int)\n",
    "\n",
    "df2['CategoricalAge']=pd.cut(df2['Age'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CategoricalAge  Survived\n",
      "0  (-0.08, 16.0]  0.504132\n",
      "1   (16.0, 32.0]  0.354545\n",
      "2   (32.0, 48.0]  0.376000\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n"
     ]
    }
   ],
   "source": [
    "print(df2[['CategoricalAge','Survived']].groupby(['CategoricalAge'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[df2['Age']<=16,'Age']=0\n",
    "df2.loc[(df2['Age']>16)&(df2['Age']<=32),'Age']=1\n",
    "df2.loc[(df2['Age']>32)&(df2['Age']<=48),'Age']=2\n",
    "df2.loc[(df2['Age']>48)&(df2['Age']<=64),'Age']=3\n",
    "df2.loc[(df2['Age']>64),'Age']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>CategoricalAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0              1       3                            Braund, Mr. Owen Harris   \n",
       "1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2              3       3                             Heikkinen, Miss. Laina   \n",
       "3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4              5       3                           Allen, Mr. William Henry   \n",
       "5              6       3                                   Moran, Mr. James   \n",
       "6              7       1                            McCarthy, Mr. Timothy J   \n",
       "7              8       3                     Palsson, Master. Gosta Leonard   \n",
       "8              9       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9             10       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "10            11       3                    Sandstrom, Miss. Marguerite Rut   \n",
       "11            12       1                           Bonnell, Miss. Elizabeth   \n",
       "12            13       3                     Saundercock, Mr. William Henry   \n",
       "13            14       3                        Andersson, Mr. Anders Johan   \n",
       "14            15       3               Vestrom, Miss. Hulda Amanda Adolfina   \n",
       "15            16       2                   Hewlett, Mrs. (Mary D Kingcome)    \n",
       "16            17       3                               Rice, Master. Eugene   \n",
       "17            18       2                       Williams, Mr. Charles Eugene   \n",
       "18            19       3  Vander Planke, Mrs. Julius (Emelia Maria Vande...   \n",
       "19            20       3                            Masselmani, Mrs. Fatima   \n",
       "20            21       2                               Fynney, Mr. Joseph J   \n",
       "21            22       2                              Beesley, Mr. Lawrence   \n",
       "22            23       3                        McGowan, Miss. Anna \"Annie\"   \n",
       "23            24       1                       Sloper, Mr. William Thompson   \n",
       "24            25       3                      Palsson, Miss. Torborg Danira   \n",
       "25            26       3  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...   \n",
       "26            27       3                            Emir, Mr. Farred Chehab   \n",
       "27            28       1                     Fortune, Mr. Charles Alexander   \n",
       "28            29       3                      O'Dwyer, Miss. Ellen \"Nellie\"   \n",
       "29            30       3                                Todoroff, Mr. Lalio   \n",
       "..           ...     ...                                                ...   \n",
       "861          862       2                        Giles, Mr. Frederick Edward   \n",
       "862          863       1  Swift, Mrs. Frederick Joel (Margaret Welles Ba...   \n",
       "863          864       3                  Sage, Miss. Dorothy Edith \"Dolly\"   \n",
       "864          865       2                             Gill, Mr. John William   \n",
       "865          866       2                           Bystrom, Mrs. (Karolina)   \n",
       "866          867       2                       Duran y More, Miss. Asuncion   \n",
       "867          868       1               Roebling, Mr. Washington Augustus II   \n",
       "868          869       3                        van Melkebeke, Mr. Philemon   \n",
       "869          870       3                    Johnson, Master. Harold Theodor   \n",
       "870          871       3                                  Balkic, Mr. Cerin   \n",
       "871          872       1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
       "872          873       1                           Carlsson, Mr. Frans Olof   \n",
       "873          874       3                        Vander Cruyssen, Mr. Victor   \n",
       "874          875       2              Abelson, Mrs. Samuel (Hannah Wizosky)   \n",
       "875          876       3                   Najib, Miss. Adele Kiamie \"Jane\"   \n",
       "876          877       3                      Gustafsson, Mr. Alfred Ossian   \n",
       "877          878       3                               Petroff, Mr. Nedelio   \n",
       "878          879       3                                 Laleff, Mr. Kristo   \n",
       "879          880       1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   \n",
       "880          881       2       Shelley, Mrs. William (Imanita Parrish Hall)   \n",
       "881          882       3                                 Markun, Mr. Johann   \n",
       "882          883       3                       Dahlberg, Miss. Gerda Ulrika   \n",
       "883          884       2                      Banfield, Mr. Frederick James   \n",
       "884          885       3                             Sutehall, Mr. Henry Jr   \n",
       "885          886       3               Rice, Mrs. William (Margaret Norton)   \n",
       "886          887       2                              Montvila, Rev. Juozas   \n",
       "887          888       1                       Graham, Miss. Margaret Edith   \n",
       "888          889       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890       1                              Behr, Mr. Karl Howell   \n",
       "890          891       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex  Age  SibSp  Parch            Ticket      Fare        Cabin  \\\n",
       "0      male    1      1      0         A/5 21171    7.2500          NaN   \n",
       "1    female    2      1      0          PC 17599   71.2833          C85   \n",
       "2    female    1      0      0  STON/O2. 3101282    7.9250          NaN   \n",
       "3    female    2      1      0            113803   53.1000         C123   \n",
       "4      male    2      0      0            373450    8.0500          NaN   \n",
       "5      male    2      0      0            330877    8.4583          NaN   \n",
       "6      male    3      0      0             17463   51.8625          E46   \n",
       "7      male    0      3      1            349909   21.0750          NaN   \n",
       "8    female    1      0      2            347742   11.1333          NaN   \n",
       "9    female    0      1      0            237736   30.0708          NaN   \n",
       "10   female    0      1      1           PP 9549   16.7000           G6   \n",
       "11   female    3      0      0            113783   26.5500         C103   \n",
       "12     male    1      0      0         A/5. 2151    8.0500          NaN   \n",
       "13     male    2      1      5            347082   31.2750          NaN   \n",
       "14   female    0      0      0            350406    7.8542          NaN   \n",
       "15   female    3      0      0            248706   16.0000          NaN   \n",
       "16     male    0      4      1            382652   29.1250          NaN   \n",
       "17     male    2      0      0            244373   13.0000          NaN   \n",
       "18   female    1      1      0            345763   18.0000          NaN   \n",
       "19   female    1      0      0              2649    7.2250          NaN   \n",
       "20     male    2      0      0            239865   26.0000          NaN   \n",
       "21     male    2      0      0            248698   13.0000          D56   \n",
       "22   female    0      0      0            330923    8.0292          NaN   \n",
       "23     male    1      0      0            113788   35.5000           A6   \n",
       "24   female    0      3      1            349909   21.0750          NaN   \n",
       "25   female    2      1      5            347077   31.3875          NaN   \n",
       "26     male    1      0      0              2631    7.2250          NaN   \n",
       "27     male    1      3      2             19950  263.0000  C23 C25 C27   \n",
       "28   female    2      0      0            330959    7.8792          NaN   \n",
       "29     male    1      0      0            349216    7.8958          NaN   \n",
       "..      ...  ...    ...    ...               ...       ...          ...   \n",
       "861    male    1      1      0             28134   11.5000          NaN   \n",
       "862  female    2      0      0             17466   25.9292          D17   \n",
       "863  female    2      8      2          CA. 2343   69.5500          NaN   \n",
       "864    male    1      0      0            233866   13.0000          NaN   \n",
       "865  female    2      0      0            236852   13.0000          NaN   \n",
       "866  female    1      1      0     SC/PARIS 2149   13.8583          NaN   \n",
       "867    male    1      0      0          PC 17590   50.4958          A24   \n",
       "868    male    1      0      0            345777    9.5000          NaN   \n",
       "869    male    0      1      1            347742   11.1333          NaN   \n",
       "870    male    1      0      0            349248    7.8958          NaN   \n",
       "871  female    2      1      1             11751   52.5542          D35   \n",
       "872    male    2      0      0               695    5.0000  B51 B53 B55   \n",
       "873    male    2      0      0            345765    9.0000          NaN   \n",
       "874  female    1      1      0         P/PP 3381   24.0000          NaN   \n",
       "875  female    0      0      0              2667    7.2250          NaN   \n",
       "876    male    1      0      0              7534    9.8458          NaN   \n",
       "877    male    1      0      0            349212    7.8958          NaN   \n",
       "878    male    1      0      0            349217    7.8958          NaN   \n",
       "879  female    3      0      1             11767   83.1583          C50   \n",
       "880  female    1      0      1            230433   26.0000          NaN   \n",
       "881    male    2      0      0            349257    7.8958          NaN   \n",
       "882  female    1      0      0              7552   10.5167          NaN   \n",
       "883    male    1      0      0  C.A./SOTON 34068   10.5000          NaN   \n",
       "884    male    1      0      0   SOTON/OQ 392076    7.0500          NaN   \n",
       "885  female    2      0      5            382652   29.1250          NaN   \n",
       "886    male    1      0      0            211536   13.0000          NaN   \n",
       "887  female    1      0      0            112053   30.0000          B42   \n",
       "888  female    2      1      2        W./C. 6607   23.4500          NaN   \n",
       "889    male    1      0      0            111369   30.0000         C148   \n",
       "890    male    1      0      0            370376    7.7500          NaN   \n",
       "\n",
       "    Embarked  Survived CategoricalAge  \n",
       "0          S         0   (16.0, 32.0]  \n",
       "1          C         1   (32.0, 48.0]  \n",
       "2          S         1   (16.0, 32.0]  \n",
       "3          S         1   (32.0, 48.0]  \n",
       "4          S         0   (32.0, 48.0]  \n",
       "5          Q         0   (32.0, 48.0]  \n",
       "6          S         0   (48.0, 64.0]  \n",
       "7          S         0  (-0.08, 16.0]  \n",
       "8          S         1   (16.0, 32.0]  \n",
       "9          C         1  (-0.08, 16.0]  \n",
       "10         S         1  (-0.08, 16.0]  \n",
       "11         S         1   (48.0, 64.0]  \n",
       "12         S         0   (16.0, 32.0]  \n",
       "13         S         0   (32.0, 48.0]  \n",
       "14         S         0  (-0.08, 16.0]  \n",
       "15         S         1   (48.0, 64.0]  \n",
       "16         Q         0  (-0.08, 16.0]  \n",
       "17         S         1   (32.0, 48.0]  \n",
       "18         S         0   (16.0, 32.0]  \n",
       "19         C         1   (16.0, 32.0]  \n",
       "20         S         0   (32.0, 48.0]  \n",
       "21         S         1   (32.0, 48.0]  \n",
       "22         Q         1  (-0.08, 16.0]  \n",
       "23         S         1   (16.0, 32.0]  \n",
       "24         S         0  (-0.08, 16.0]  \n",
       "25         S         1   (32.0, 48.0]  \n",
       "26         C         0   (16.0, 32.0]  \n",
       "27         S         0   (16.0, 32.0]  \n",
       "28         Q         1   (32.0, 48.0]  \n",
       "29         S         0   (16.0, 32.0]  \n",
       "..       ...       ...            ...  \n",
       "861        S         0   (16.0, 32.0]  \n",
       "862        S         1   (32.0, 48.0]  \n",
       "863        S         0   (32.0, 48.0]  \n",
       "864        S         0   (16.0, 32.0]  \n",
       "865        S         1   (32.0, 48.0]  \n",
       "866        C         1   (16.0, 32.0]  \n",
       "867        S         0   (16.0, 32.0]  \n",
       "868        S         0   (16.0, 32.0]  \n",
       "869        S         1  (-0.08, 16.0]  \n",
       "870        S         0   (16.0, 32.0]  \n",
       "871        S         1   (32.0, 48.0]  \n",
       "872        S         0   (32.0, 48.0]  \n",
       "873        S         0   (32.0, 48.0]  \n",
       "874        C         1   (16.0, 32.0]  \n",
       "875        C         1  (-0.08, 16.0]  \n",
       "876        S         0   (16.0, 32.0]  \n",
       "877        S         0   (16.0, 32.0]  \n",
       "878        S         0   (16.0, 32.0]  \n",
       "879        C         1   (48.0, 64.0]  \n",
       "880        S         1   (16.0, 32.0]  \n",
       "881        S         0   (32.0, 48.0]  \n",
       "882        S         0   (16.0, 32.0]  \n",
       "883        S         0   (16.0, 32.0]  \n",
       "884        S         0   (16.0, 32.0]  \n",
       "885        Q         0   (32.0, 48.0]  \n",
       "886        S         0   (16.0, 32.0]  \n",
       "887        S         1   (16.0, 32.0]  \n",
       "888        S         0   (32.0, 48.0]  \n",
       "889        C         1   (16.0, 32.0]  \n",
       "890        Q         0   (16.0, 32.0]  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Age']=df2['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>862</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>865</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>867</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>868</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>877</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>878</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>879</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>883</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>886</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Embarked  FamilySize  Fare  IsAlone  Parch  PassengerId  Pclass  \\\n",
       "0      1         0           2   0.0        0      0            1       3   \n",
       "1      2         1           2   3.0        0      0            2       1   \n",
       "2      1         0           1   1.0        1      0            3       3   \n",
       "3      2         0           2   3.0        0      0            4       1   \n",
       "4      2         0           1   1.0        1      0            5       3   \n",
       "5      2         2           1   1.0        1      0            6       3   \n",
       "6      3         0           1   3.0        1      0            7       1   \n",
       "7      0         0           5   2.0        0      1            8       3   \n",
       "8      1         0           3   1.0        0      2            9       3   \n",
       "9      0         1           2   2.0        0      0           10       2   \n",
       "10     0         0           3   2.0        0      1           11       3   \n",
       "11     3         0           1   2.0        1      0           12       1   \n",
       "12     1         0           1   1.0        1      0           13       3   \n",
       "13     2         0           7   3.0        0      5           14       3   \n",
       "14     0         0           1   0.0        1      0           15       3   \n",
       "15     3         0           1   2.0        1      0           16       2   \n",
       "16     0         2           6   2.0        0      1           17       3   \n",
       "17     2         0           1   1.0        1      0           18       2   \n",
       "18     1         0           2   2.0        0      0           19       3   \n",
       "19     1         1           1   0.0        1      0           20       3   \n",
       "20     2         0           1   2.0        1      0           21       2   \n",
       "21     2         0           1   1.0        1      0           22       2   \n",
       "22     0         2           1   1.0        1      0           23       3   \n",
       "23     1         0           1   3.0        1      0           24       1   \n",
       "24     0         0           5   2.0        0      1           25       3   \n",
       "25     2         0           7   3.0        0      5           26       3   \n",
       "26     1         1           1   0.0        1      0           27       3   \n",
       "27     1         0           6   3.0        0      2           28       1   \n",
       "28     2         2           1   0.0        1      0           29       3   \n",
       "29     1         0           1   0.0        1      0           30       3   \n",
       "..   ...       ...         ...   ...      ...    ...          ...     ...   \n",
       "861    1         0           2   1.0        0      0          862       2   \n",
       "862    2         0           1   2.0        1      0          863       1   \n",
       "863    2         0          11   3.0        0      2          864       3   \n",
       "864    1         0           1   1.0        1      0          865       2   \n",
       "865    2         0           1   1.0        1      0          866       2   \n",
       "866    1         1           2   1.0        0      0          867       2   \n",
       "867    1         0           1   3.0        1      0          868       1   \n",
       "868    1         0           1   1.0        1      0          869       3   \n",
       "869    0         0           3   1.0        0      1          870       3   \n",
       "870    1         0           1   0.0        1      0          871       3   \n",
       "871    2         0           3   3.0        0      1          872       1   \n",
       "872    2         0           1   0.0        1      0          873       1   \n",
       "873    2         0           1   1.0        1      0          874       3   \n",
       "874    1         1           2   2.0        0      0          875       2   \n",
       "875    0         1           1   0.0        1      0          876       3   \n",
       "876    1         0           1   1.0        1      0          877       3   \n",
       "877    1         0           1   0.0        1      0          878       3   \n",
       "878    1         0           1   0.0        1      0          879       3   \n",
       "879    3         1           2   3.0        0      1          880       1   \n",
       "880    1         0           2   2.0        0      1          881       2   \n",
       "881    2         0           1   0.0        1      0          882       3   \n",
       "882    1         0           1   1.0        1      0          883       3   \n",
       "883    1         0           1   1.0        1      0          884       2   \n",
       "884    1         0           1   0.0        1      0          885       3   \n",
       "885    2         2           6   2.0        0      5          886       3   \n",
       "886    1         0           1   1.0        1      0          887       2   \n",
       "887    1         0           1   2.0        1      0          888       1   \n",
       "888    2         0           4   2.0        0      2          889       3   \n",
       "889    1         1           1   2.0        1      0          890       1   \n",
       "890    1         2           1   0.0        1      0          891       3   \n",
       "\n",
       "     Sex  SibSp  Survived  \n",
       "0      1      1         0  \n",
       "1      0      1         1  \n",
       "2      0      0         1  \n",
       "3      0      1         1  \n",
       "4      1      0         0  \n",
       "5      1      0         0  \n",
       "6      1      0         0  \n",
       "7      1      3         0  \n",
       "8      0      0         1  \n",
       "9      0      1         1  \n",
       "10     0      1         1  \n",
       "11     0      0         1  \n",
       "12     1      0         0  \n",
       "13     1      1         0  \n",
       "14     0      0         0  \n",
       "15     0      0         1  \n",
       "16     1      4         0  \n",
       "17     1      0         1  \n",
       "18     0      1         0  \n",
       "19     0      0         1  \n",
       "20     1      0         0  \n",
       "21     1      0         1  \n",
       "22     0      0         1  \n",
       "23     1      0         1  \n",
       "24     0      3         0  \n",
       "25     0      1         1  \n",
       "26     1      0         0  \n",
       "27     1      3         0  \n",
       "28     0      0         1  \n",
       "29     1      0         0  \n",
       "..   ...    ...       ...  \n",
       "861    1      1         0  \n",
       "862    0      0         1  \n",
       "863    0      8         0  \n",
       "864    1      0         0  \n",
       "865    0      0         1  \n",
       "866    0      1         1  \n",
       "867    1      0         0  \n",
       "868    1      0         0  \n",
       "869    1      1         1  \n",
       "870    1      0         0  \n",
       "871    0      1         1  \n",
       "872    1      0         0  \n",
       "873    1      0         0  \n",
       "874    0      1         1  \n",
       "875    0      0         1  \n",
       "876    1      0         0  \n",
       "877    1      0         0  \n",
       "878    1      0         0  \n",
       "879    0      0         1  \n",
       "880    0      0         1  \n",
       "881    1      0         0  \n",
       "882    0      0         0  \n",
       "883    1      0         0  \n",
       "884    1      0         0  \n",
       "885    0      0         0  \n",
       "886    1      0         0  \n",
       "887    0      0         1  \n",
       "888    0      1         0  \n",
       "889    1      0         1  \n",
       "890    1      0         0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Embarked  FamilySize  Fare  IsAlone  Parch  PassengerId  Pclass  Sex  \\\n",
       "0    1         0           2   0.0        0      0            1       3    1   \n",
       "1    2         1           2   3.0        0      0            2       1    0   \n",
       "2    1         0           1   1.0        1      0            3       3    0   \n",
       "3    2         0           2   3.0        0      0            4       1    0   \n",
       "4    2         0           1   1.0        1      0            5       3    1   \n",
       "\n",
       "   SibSp  Survived  \n",
       "0      1         0  \n",
       "1      1         1  \n",
       "2      0         1  \n",
       "3      1         1  \n",
       "4      0         0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "print(df1['Age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove =['Parch','SibSp','Cabin','Name','PassengerId']\n",
    "df1=df1[df1.columns.difference(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Embarked  FamilySize  Fare  IsAlone  Pclass  Sex  Survived\n",
       "0     1         0           2   0.0        0       3    1         0\n",
       "1     2         1           2   3.0        0       1    0         1\n",
       "2     1         0           1   1.0        1       3    0         1\n",
       "3     2         0           2   3.0        0       1    0         1\n",
       "4     2         0           1   1.0        1       3    1         0\n",
       "5     2         2           1   1.0        1       3    1         0\n",
       "6     3         0           1   3.0        1       1    1         0\n",
       "7     0         0           5   2.0        0       3    1         0\n",
       "8     1         0           3   1.0        0       3    0         1\n",
       "9     0         1           2   2.0        0       2    0         1\n",
       "10    0         0           3   2.0        0       3    0         1\n",
       "11    3         0           1   2.0        1       1    0         1\n",
       "12    1         0           1   1.0        1       3    1         0\n",
       "13    2         0           7   3.0        0       3    1         0\n",
       "14    0         0           1   0.0        1       3    0         0\n",
       "15    3         0           1   2.0        1       2    0         1\n",
       "16    0         2           6   2.0        0       3    1         0\n",
       "17    2         0           1   1.0        1       2    1         1\n",
       "18    1         0           2   2.0        0       3    0         0\n",
       "19    1         1           1   0.0        1       3    0         1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1[df1.columns[0:7]].values\n",
    "y=df1[df1.columns[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels=len(labels)\n",
    "    n_unique_labels=len(np.unique(labels))\n",
    "    one_hot_encode=np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels]=1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the dependent variable\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y=encoder.transform(y)\n",
    "y=one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data set and mix up the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=shuffle(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.20,random_state=415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the shape of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 7)\n",
      "(712, 2)\n",
      "(179, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the important parameters and variables to work with the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 7\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.3\n",
    "training_epochs=1000\n",
    "cost_history=[]\n",
    "n_dim=X.shape[1]\n",
    "print(\"n_dim\",n_dim)\n",
    "n_class=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"C:\\\\Users\\\\ayana\\\\Documents\\\\ML\\\\Machine Learning With Python\\\\model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "n_hidden_4=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,n_dim])\n",
    "W=tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b=tf.Variable(tf.zeros([n_class]))\n",
    "y_=tf.placeholder(tf.float32,[None,n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    # Hidden Layer with RELU activation\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    # Hidden layer with sigmoid activation\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    #Output layer with Linear activation\n",
    "    \n",
    "    out_layer=tf.matmul(layer_4,weights['out'])+biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the weights and biases for each layer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y,labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the cost and accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 1.54787 -MSE: 30.3119400436 -Train Accuracy: 0.38764\n",
      "epoch: 1 - cost: 2.28159 -MSE: 36.3646603355 -Train Accuracy: 0.61236\n",
      "epoch: 2 - cost: 0.704318 -MSE: 28.4158180452 -Train Accuracy: 0.429775\n",
      "epoch: 3 - cost: 0.936873 -MSE: 29.2224554345 -Train Accuracy: 0.61236\n",
      "epoch: 4 - cost: 1.48287 -MSE: 29.9178861975 -Train Accuracy: 0.38764\n",
      "epoch: 5 - cost: 2.2546 -MSE: 36.0181233185 -Train Accuracy: 0.61236\n",
      "epoch: 6 - cost: 0.702346 -MSE: 28.1997043676 -Train Accuracy: 0.428371\n",
      "epoch: 7 - cost: 0.95684 -MSE: 29.1076577673 -Train Accuracy: 0.61236\n",
      "epoch: 8 - cost: 1.48933 -MSE: 29.7352544596 -Train Accuracy: 0.38764\n",
      "epoch: 9 - cost: 2.2438 -MSE: 35.8105410303 -Train Accuracy: 0.61236\n",
      "epoch: 10 - cost: 0.696051 -MSE: 28.0071307588 -Train Accuracy: 0.505618\n",
      "epoch: 11 - cost: 0.947865 -MSE: 28.9213655372 -Train Accuracy: 0.61236\n",
      "epoch: 12 - cost: 1.47566 -MSE: 29.533270872 -Train Accuracy: 0.38764\n",
      "epoch: 13 - cost: 2.22989 -MSE: 35.6028100151 -Train Accuracy: 0.61236\n",
      "epoch: 14 - cost: 0.692198 -MSE: 27.8468110542 -Train Accuracy: 0.52809\n",
      "epoch: 15 - cost: 0.948676 -MSE: 28.7944290541 -Train Accuracy: 0.61236\n",
      "epoch: 16 - cost: 1.46864 -MSE: 29.3753441062 -Train Accuracy: 0.38764\n",
      "epoch: 17 - cost: 2.21847 -MSE: 35.4352498204 -Train Accuracy: 0.61236\n",
      "epoch: 18 - cost: 0.688238 -MSE: 27.7123619498 -Train Accuracy: 0.530899\n",
      "epoch: 19 - cost: 0.94678 -MSE: 28.6824190551 -Train Accuracy: 0.61236\n",
      "epoch: 20 - cost: 1.46028 -MSE: 29.2396680959 -Train Accuracy: 0.38764\n",
      "epoch: 21 - cost: 2.20747 -MSE: 35.2927336443 -Train Accuracy: 0.61236\n",
      "epoch: 22 - cost: 0.684717 -MSE: 27.6029084122 -Train Accuracy: 0.533708\n",
      "epoch: 23 - cost: 0.945773 -MSE: 28.596694637 -Train Accuracy: 0.61236\n",
      "epoch: 24 - cost: 1.45266 -MSE: 29.1295622677 -Train Accuracy: 0.38764\n",
      "epoch: 25 - cost: 2.19711 -MSE: 35.1765959182 -Train Accuracy: 0.61236\n",
      "epoch: 26 - cost: 0.681365 -MSE: 27.5165960114 -Train Accuracy: 0.537921\n",
      "epoch: 27 - cost: 0.944655 -MSE: 28.5328271562 -Train Accuracy: 0.61236\n",
      "epoch: 28 - cost: 1.44507 -MSE: 29.0418731631 -Train Accuracy: 0.38764\n",
      "epoch: 29 - cost: 2.18702 -MSE: 35.0837363224 -Train Accuracy: 0.61236\n",
      "epoch: 30 - cost: 0.678208 -MSE: 27.4522723549 -Train Accuracy: 0.542135\n",
      "epoch: 31 - cost: 0.943783 -MSE: 28.4912147919 -Train Accuracy: 0.61236\n",
      "epoch: 32 - cost: 1.43758 -MSE: 28.975500194 -Train Accuracy: 0.38764\n",
      "epoch: 33 - cost: 2.17701 -MSE: 35.0123086367 -Train Accuracy: 0.61236\n",
      "epoch: 34 - cost: 0.675233 -MSE: 27.4087532487 -Train Accuracy: 0.606742\n",
      "epoch: 35 - cost: 0.943181 -MSE: 28.4709672183 -Train Accuracy: 0.61236\n",
      "epoch: 36 - cost: 1.43009 -MSE: 28.9288885021 -Train Accuracy: 0.38764\n",
      "epoch: 37 - cost: 2.16692 -MSE: 34.960082915 -Train Accuracy: 0.61236\n",
      "epoch: 38 - cost: 0.672467 -MSE: 27.3847579556 -Train Accuracy: 0.608146\n",
      "epoch: 39 - cost: 0.942988 -MSE: 28.4713310238 -Train Accuracy: 0.61236\n",
      "epoch: 40 - cost: 1.42257 -MSE: 28.9005067585 -Train Accuracy: 0.38764\n",
      "epoch: 41 - cost: 2.15661 -MSE: 34.924832792 -Train Accuracy: 0.61236\n",
      "epoch: 42 - cost: 0.669934 -MSE: 27.3786844731 -Train Accuracy: 0.609551\n",
      "epoch: 43 - cost: 0.943289 -MSE: 28.4910107958 -Train Accuracy: 0.61236\n",
      "epoch: 44 - cost: 1.41502 -MSE: 28.8884951117 -Train Accuracy: 0.38764\n",
      "epoch: 45 - cost: 2.14603 -MSE: 34.9043420128 -Train Accuracy: 0.61236\n",
      "epoch: 46 - cost: 0.667648 -MSE: 27.3885520856 -Train Accuracy: 0.609551\n",
      "epoch: 47 - cost: 0.944121 -MSE: 28.5282060538 -Train Accuracy: 0.61236\n",
      "epoch: 48 - cost: 1.40738 -MSE: 28.8907250962 -Train Accuracy: 0.38764\n",
      "epoch: 49 - cost: 2.13515 -MSE: 34.8964358998 -Train Accuracy: 0.61236\n",
      "epoch: 50 - cost: 0.665599 -MSE: 27.4120971706 -Train Accuracy: 0.619382\n",
      "epoch: 51 - cost: 0.945442 -MSE: 28.5806362172 -Train Accuracy: 0.61236\n",
      "epoch: 52 - cost: 1.3996 -MSE: 28.9048372838 -Train Accuracy: 0.38764\n",
      "epoch: 53 - cost: 2.12397 -MSE: 34.8989370607 -Train Accuracy: 0.61236\n",
      "epoch: 54 - cost: 0.66377 -MSE: 27.4469202238 -Train Accuracy: 0.619382\n",
      "epoch: 55 - cost: 0.947185 -MSE: 28.6458143699 -Train Accuracy: 0.61236\n",
      "epoch: 56 - cost: 1.39163 -MSE: 28.9283994992 -Train Accuracy: 0.38764\n",
      "epoch: 57 - cost: 2.11247 -MSE: 34.9096133364 -Train Accuracy: 0.61236\n",
      "epoch: 58 - cost: 0.662145 -MSE: 27.4906205577 -Train Accuracy: 0.623595\n",
      "epoch: 59 - cost: 0.949289 -MSE: 28.7212606594 -Train Accuracy: 0.61236\n",
      "epoch: 60 - cost: 1.38342 -MSE: 28.9590654275 -Train Accuracy: 0.38764\n",
      "epoch: 61 - cost: 2.10064 -MSE: 34.9261311772 -Train Accuracy: 0.61236\n",
      "epoch: 62 - cost: 0.660719 -MSE: 27.5408909897 -Train Accuracy: 0.626405\n",
      "epoch: 63 - cost: 0.951726 -MSE: 28.8046342864 -Train Accuracy: 0.61236\n",
      "epoch: 64 - cost: 1.37492 -MSE: 28.9946411891 -Train Accuracy: 0.38764\n",
      "epoch: 65 - cost: 2.08848 -MSE: 34.9461559783 -Train Accuracy: 0.61236\n",
      "epoch: 66 - cost: 0.659499 -MSE: 27.5956262419 -Train Accuracy: 0.626405\n",
      "epoch: 67 - cost: 0.954505 -MSE: 28.8938298695 -Train Accuracy: 0.61236\n",
      "epoch: 68 - cost: 1.36614 -MSE: 29.0332062237 -Train Accuracy: 0.38764\n",
      "epoch: 69 - cost: 2.07597 -MSE: 34.9674930773 -Train Accuracy: 0.61236\n",
      "epoch: 70 - cost: 0.658497 -MSE: 27.652979509 -Train Accuracy: 0.633427\n",
      "epoch: 71 - cost: 0.957651 -MSE: 28.9870250715 -Train Accuracy: 0.61236\n",
      "epoch: 72 - cost: 1.35708 -MSE: 29.0731528289 -Train Accuracy: 0.38764\n",
      "epoch: 73 - cost: 2.06314 -MSE: 34.9882322711 -Train Accuracy: 0.61236\n",
      "epoch: 74 - cost: 0.657734 -MSE: 27.7114857547 -Train Accuracy: 0.636236\n",
      "epoch: 75 - cost: 0.961198 -MSE: 29.0827965585 -Train Accuracy: 0.61236\n",
      "epoch: 76 - cost: 1.34776 -MSE: 29.1132686558 -Train Accuracy: 0.38764\n",
      "epoch: 77 - cost: 2.05 -MSE: 35.0068636677 -Train Accuracy: 0.61236\n",
      "epoch: 78 - cost: 0.65723 -MSE: 27.7701072364 -Train Accuracy: 0.66573\n",
      "epoch: 79 - cost: 0.96518 -MSE: 29.1801551048 -Train Accuracy: 0.61236\n",
      "epoch: 80 - cost: 1.33819 -MSE: 29.1527331927 -Train Accuracy: 0.38764\n",
      "epoch: 81 - cost: 2.03654 -MSE: 35.022323231 -Train Accuracy: 0.61236\n",
      "epoch: 82 - cost: 0.657005 -MSE: 27.8282194514 -Train Accuracy: 0.66573\n",
      "epoch: 83 - cost: 0.969625 -MSE: 29.2785232779 -Train Accuracy: 0.61236\n",
      "epoch: 84 - cost: 1.32838 -MSE: 29.1910386852 -Train Accuracy: 0.38764\n",
      "epoch: 85 - cost: 2.02276 -MSE: 35.0338756029 -Train Accuracy: 0.61236\n",
      "epoch: 86 - cost: 0.657084 -MSE: 27.8855241017 -Train Accuracy: 0.668539\n",
      "epoch: 87 - cost: 0.974567 -MSE: 29.3777185044 -Train Accuracy: 0.61236\n",
      "epoch: 88 - cost: 1.3183 -MSE: 29.2279269369 -Train Accuracy: 0.38764\n",
      "epoch: 89 - cost: 2.00864 -MSE: 35.0410408704 -Train Accuracy: 0.61236\n",
      "epoch: 90 - cost: 0.65749 -MSE: 27.9419448199 -Train Accuracy: 0.668539\n",
      "epoch: 91 - cost: 0.98004 -MSE: 29.477798799 -Train Accuracy: 0.61236\n",
      "epoch: 92 - cost: 1.30794 -MSE: 29.2632554767 -Train Accuracy: 0.38764\n",
      "epoch: 93 - cost: 1.99412 -MSE: 35.0434626059 -Train Accuracy: 0.61236\n",
      "epoch: 94 - cost: 0.658255 -MSE: 27.9975335466 -Train Accuracy: 0.668539\n",
      "epoch: 95 - cost: 0.986084 -MSE: 29.5790074039 -Train Accuracy: 0.61236\n",
      "epoch: 96 - cost: 1.29727 -MSE: 29.2969464247 -Train Accuracy: 0.38764\n",
      "epoch: 97 - cost: 1.97915 -MSE: 35.0408034537 -Train Accuracy: 0.61236\n",
      "epoch: 98 - cost: 0.659411 -MSE: 28.0523800533 -Train Accuracy: 0.668539\n",
      "epoch: 99 - cost: 0.992746 -MSE: 29.6816790137 -Train Accuracy: 0.61236\n",
      "epoch: 100 - cost: 1.28625 -MSE: 29.3289047151 -Train Accuracy: 0.38764\n",
      "epoch: 101 - cost: 1.96366 -MSE: 35.0326983016 -Train Accuracy: 0.61236\n",
      "epoch: 102 - cost: 0.660995 -MSE: 28.1065959749 -Train Accuracy: 0.668539\n",
      "epoch: 103 - cost: 1.00008 -MSE: 29.786189337 -Train Accuracy: 0.61236\n",
      "epoch: 104 - cost: 1.27482 -MSE: 29.3590106027 -Train Accuracy: 0.38764\n",
      "epoch: 105 - cost: 1.94757 -MSE: 35.0187189777 -Train Accuracy: 0.61236\n",
      "epoch: 106 - cost: 0.663052 -MSE: 28.1602747155 -Train Accuracy: 0.668539\n",
      "epoch: 107 - cost: 1.00814 -MSE: 29.8929534062 -Train Accuracy: 0.61236\n",
      "epoch: 108 - cost: 1.26292 -MSE: 29.3871108443 -Train Accuracy: 0.38764\n",
      "epoch: 109 - cost: 1.93076 -MSE: 34.9983750065 -Train Accuracy: 0.61236\n",
      "epoch: 110 - cost: 0.665634 -MSE: 28.2135205727 -Train Accuracy: 0.668539\n",
      "epoch: 111 - cost: 1.017 -MSE: 30.0024041595 -Train Accuracy: 0.61236\n",
      "epoch: 112 - cost: 1.2505 -MSE: 29.4130136659 -Train Accuracy: 0.38764\n",
      "epoch: 113 - cost: 1.91316 -MSE: 34.9711367728 -Train Accuracy: 0.61236\n",
      "epoch: 114 - cost: 0.668794 -MSE: 28.2664234941 -Train Accuracy: 0.668539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115 - cost: 1.02672 -MSE: 30.1149521238 -Train Accuracy: 0.61236\n",
      "epoch: 116 - cost: 1.23749 -MSE: 29.4365122219 -Train Accuracy: 0.38764\n",
      "epoch: 117 - cost: 1.89463 -MSE: 34.9364091564 -Train Accuracy: 0.61236\n",
      "epoch: 118 - cost: 0.672594 -MSE: 28.3190755997 -Train Accuracy: 0.668539\n",
      "epoch: 119 - cost: 1.03737 -MSE: 30.2310257811 -Train Accuracy: 0.61236\n",
      "epoch: 120 - cost: 1.22382 -MSE: 29.4573779192 -Train Accuracy: 0.38764\n",
      "epoch: 121 - cost: 1.87509 -MSE: 34.8935780131 -Train Accuracy: 0.61236\n",
      "epoch: 122 - cost: 0.677104 -MSE: 28.3715775806 -Train Accuracy: 0.668539\n",
      "epoch: 123 - cost: 1.049 -MSE: 30.3510270886 -Train Accuracy: 0.61236\n",
      "epoch: 124 - cost: 1.2094 -MSE: 29.4753666236 -Train Accuracy: 0.38764\n",
      "epoch: 125 - cost: 1.85439 -MSE: 34.8419779887 -Train Accuracy: 0.61236\n",
      "epoch: 126 - cost: 0.682399 -MSE: 28.424045058 -Train Accuracy: 0.667135\n",
      "epoch: 127 - cost: 1.06167 -MSE: 30.4753453211 -Train Accuracy: 0.61236\n",
      "epoch: 128 - cost: 1.19417 -MSE: 29.4902251293 -Train Accuracy: 0.38764\n",
      "epoch: 129 - cost: 1.83241 -MSE: 34.7808889601 -Train Accuracy: 0.61236\n",
      "epoch: 130 - cost: 0.688563 -MSE: 28.4766083468 -Train Accuracy: 0.664326\n",
      "epoch: 131 - cost: 1.07543 -MSE: 30.6043410412 -Train Accuracy: 0.61236\n",
      "epoch: 132 - cost: 1.17806 -MSE: 29.5016744735 -Train Accuracy: 0.38764\n",
      "epoch: 133 - cost: 1.80901 -MSE: 34.7095221907 -Train Accuracy: 0.61236\n",
      "epoch: 134 - cost: 0.69569 -MSE: 28.5293956133 -Train Accuracy: 0.664326\n",
      "epoch: 135 - cost: 1.09033 -MSE: 30.7383223586 -Train Accuracy: 0.61236\n",
      "epoch: 136 - cost: 1.16099 -MSE: 29.5094230875 -Train Accuracy: 0.38764\n",
      "epoch: 137 - cost: 1.78402 -MSE: 34.6269802106 -Train Accuracy: 0.61236\n",
      "epoch: 138 - cost: 0.703885 -MSE: 28.5825563748 -Train Accuracy: 0.640449\n",
      "epoch: 139 - cost: 1.1064 -MSE: 30.8775077475 -Train Accuracy: 0.61236\n",
      "epoch: 140 - cost: 1.14289 -MSE: 29.5131514638 -Train Accuracy: 0.38764\n",
      "epoch: 141 - cost: 1.75728 -MSE: 34.5322795537 -Train Accuracy: 0.61236\n",
      "epoch: 142 - cost: 0.713259 -MSE: 28.6362320724 -Train Accuracy: 0.640449\n",
      "epoch: 143 - cost: 1.12362 -MSE: 31.0219833912 -Train Accuracy: 0.61236\n",
      "epoch: 144 - cost: 1.12372 -MSE: 29.51253267 -Train Accuracy: 0.38764\n",
      "epoch: 145 - cost: 1.7286 -MSE: 34.4243367972 -Train Accuracy: 0.61236\n",
      "epoch: 146 - cost: 0.723929 -MSE: 28.6905683263 -Train Accuracy: 0.63764\n",
      "epoch: 147 - cost: 1.14198 -MSE: 31.1715943939 -Train Accuracy: 0.61236\n",
      "epoch: 148 - cost: 1.10347 -MSE: 29.5072412169 -Train Accuracy: 0.38764\n",
      "epoch: 149 - cost: 1.69778 -MSE: 34.3021004552 -Train Accuracy: 0.61236\n",
      "epoch: 150 - cost: 0.735999 -MSE: 28.7456795977 -Train Accuracy: 0.63764\n",
      "epoch: 151 - cost: 1.16137 -MSE: 31.3258121425 -Train Accuracy: 0.61236\n",
      "epoch: 152 - cost: 1.08215 -MSE: 29.4969980022 -Train Accuracy: 0.38764\n",
      "epoch: 153 - cost: 1.66468 -MSE: 34.1646502199 -Train Accuracy: 0.61236\n",
      "epoch: 154 - cost: 0.749547 -MSE: 28.8016264328 -Train Accuracy: 0.591292\n",
      "epoch: 155 - cost: 1.1816 -MSE: 31.4835412889 -Train Accuracy: 0.61236\n",
      "epoch: 156 - cost: 1.05988 -MSE: 29.4816506481 -Train Accuracy: 0.38764\n",
      "epoch: 157 - cost: 1.6292 -MSE: 34.0115062749 -Train Accuracy: 0.61236\n",
      "epoch: 158 - cost: 0.764575 -MSE: 28.8583304248 -Train Accuracy: 0.588483\n",
      "epoch: 159 - cost: 1.2023 -MSE: 31.6428000137 -Train Accuracy: 0.61236\n",
      "epoch: 160 - cost: 1.03688 -MSE: 29.4612635935 -Train Accuracy: 0.38764\n",
      "epoch: 161 - cost: 1.59138 -MSE: 33.8430191737 -Train Accuracy: 0.61236\n",
      "epoch: 162 - cost: 0.780962 -MSE: 28.9155042029 -Train Accuracy: 0.588483\n",
      "epoch: 163 - cost: 1.22292 -MSE: 31.8004228485 -Train Accuracy: 0.61236\n",
      "epoch: 164 - cost: 1.01352 -MSE: 29.4363069388 -Train Accuracy: 0.38764\n",
      "epoch: 165 - cost: 1.55151 -MSE: 33.6609483149 -Train Accuracy: 0.61236\n",
      "epoch: 166 - cost: 0.798384 -MSE: 28.9724936582 -Train Accuracy: 0.581461\n",
      "epoch: 167 - cost: 1.24263 -MSE: 31.9517701901 -Train Accuracy: 0.61236\n",
      "epoch: 168 - cost: 0.990401 -MSE: 29.4077916633 -Train Accuracy: 0.418539\n",
      "epoch: 169 - cost: 1.5102 -MSE: 33.4689922594 -Train Accuracy: 0.61236\n",
      "epoch: 170 - cost: 0.816251 -MSE: 29.0281866202 -Train Accuracy: 0.580056\n",
      "epoch: 171 - cost: 1.26034 -MSE: 32.0906808436 -Train Accuracy: 0.61236\n",
      "epoch: 172 - cost: 0.968266 -MSE: 29.3774214926 -Train Accuracy: 0.47191\n",
      "epoch: 173 - cost: 1.46843 -MSE: 33.2731360029 -Train Accuracy: 0.61236\n",
      "epoch: 174 - cost: 0.83369 -MSE: 29.0809802019 -Train Accuracy: 0.580056\n",
      "epoch: 175 - cost: 1.27478 -MSE: 32.2100114822 -Train Accuracy: 0.61236\n",
      "epoch: 176 - cost: 0.947998 -MSE: 29.3475245963 -Train Accuracy: 0.476124\n",
      "epoch: 177 - cost: 1.42755 -MSE: 33.0813211814 -Train Accuracy: 0.61236\n",
      "epoch: 178 - cost: 0.849628 -MSE: 29.1289766092 -Train Accuracy: 0.578652\n",
      "epoch: 179 - cost: 1.2847 -MSE: 32.3028398315 -Train Accuracy: 0.61236\n",
      "epoch: 180 - cost: 0.930426 -MSE: 29.3207636313 -Train Accuracy: 0.481742\n",
      "epoch: 181 - cost: 1.38905 -MSE: 32.9021992632 -Train Accuracy: 0.61236\n",
      "epoch: 182 - cost: 0.863026 -MSE: 29.1704686926 -Train Accuracy: 0.578652\n",
      "epoch: 183 - cost: 1.28919 -MSE: 32.3642948047 -Train Accuracy: 0.61236\n",
      "epoch: 184 - cost: 0.916125 -MSE: 29.2996093474 -Train Accuracy: 0.546348\n",
      "epoch: 185 - cost: 1.35418 -MSE: 32.7431378366 -Train Accuracy: 0.61236\n",
      "epoch: 186 - cost: 0.873167 -MSE: 29.2045706935 -Train Accuracy: 0.578652\n",
      "epoch: 187 - cost: 1.28797 -MSE: 32.3932580292 -Train Accuracy: 0.61236\n",
      "epoch: 188 - cost: 0.905231 -MSE: 29.2857229267 -Train Accuracy: 0.563202\n",
      "epoch: 189 - cost: 1.32358 -MSE: 32.6082515907 -Train Accuracy: 0.61236\n",
      "epoch: 190 - cost: 0.879878 -MSE: 29.2316129959 -Train Accuracy: 0.578652\n",
      "epoch: 191 - cost: 1.28148 -MSE: 32.3929404864 -Train Accuracy: 0.61236\n",
      "epoch: 192 - cost: 0.897413 -MSE: 29.2795786095 -Train Accuracy: 0.563202\n",
      "epoch: 193 - cost: 1.29717 -MSE: 32.4975785723 -Train Accuracy: 0.61236\n",
      "epoch: 194 - cost: 0.883527 -MSE: 29.253054301 -Train Accuracy: 0.578652\n",
      "epoch: 195 - cost: 1.27075 -MSE: 32.3699209841 -Train Accuracy: 0.61236\n",
      "epoch: 196 - cost: 0.891989 -MSE: 29.2805454431 -Train Accuracy: 0.577247\n",
      "epoch: 197 - cost: 1.27428 -MSE: 32.4078598484 -Train Accuracy: 0.61236\n",
      "epoch: 198 - cost: 0.884806 -MSE: 29.2709025041 -Train Accuracy: 0.578652\n",
      "epoch: 199 - cost: 1.25708 -MSE: 32.3320582185 -Train Accuracy: 0.61236\n",
      "epoch: 200 - cost: 0.888165 -MSE: 29.2872699039 -Train Accuracy: 0.578652\n",
      "epoch: 201 - cost: 1.25397 -MSE: 32.3342799859 -Train Accuracy: 0.61236\n",
      "epoch: 202 - cost: 0.884468 -MSE: 29.2870321575 -Train Accuracy: 0.580056\n",
      "epoch: 203 - cost: 1.24166 -MSE: 32.2864750404 -Train Accuracy: 0.61236\n",
      "epoch: 204 - cost: 0.885235 -MSE: 29.2981719462 -Train Accuracy: 0.580056\n",
      "epoch: 205 - cost: 1.23537 -MSE: 32.2721367134 -Train Accuracy: 0.61236\n",
      "epoch: 206 - cost: 0.883124 -MSE: 29.3027385622 -Train Accuracy: 0.580056\n",
      "epoch: 207 - cost: 1.22544 -MSE: 32.2383536098 -Train Accuracy: 0.61236\n",
      "epoch: 208 - cost: 0.882689 -MSE: 29.3118375949 -Train Accuracy: 0.580056\n",
      "epoch: 209 - cost: 1.21784 -MSE: 32.2177819199 -Train Accuracy: 0.61236\n",
      "epoch: 210 - cost: 0.881183 -MSE: 29.318673767 -Train Accuracy: 0.580056\n",
      "epoch: 211 - cost: 1.20899 -MSE: 32.190793701 -Train Accuracy: 0.61236\n",
      "epoch: 212 - cost: 0.880215 -MSE: 29.3271583043 -Train Accuracy: 0.580056\n",
      "epoch: 213 - cost: 1.20099 -MSE: 32.1687748167 -Train Accuracy: 0.61236\n",
      "epoch: 214 - cost: 0.87887 -MSE: 29.3349766821 -Train Accuracy: 0.582865\n",
      "epoch: 215 - cost: 1.19265 -MSE: 32.1452144314 -Train Accuracy: 0.61236\n",
      "epoch: 216 - cost: 0.877652 -MSE: 29.343330686 -Train Accuracy: 0.61236\n",
      "epoch: 217 - cost: 1.18462 -MSE: 32.1236056759 -Train Accuracy: 0.61236\n",
      "epoch: 218 - cost: 0.876292 -MSE: 29.3515055126 -Train Accuracy: 0.625\n",
      "epoch: 219 - cost: 1.17655 -MSE: 32.1020164686 -Train Accuracy: 0.61236\n",
      "epoch: 220 - cost: 0.874927 -MSE: 29.3597958166 -Train Accuracy: 0.629214\n",
      "epoch: 221 - cost: 1.16862 -MSE: 32.0813508494 -Train Accuracy: 0.61236\n",
      "epoch: 222 - cost: 0.873489 -MSE: 29.3679980401 -Train Accuracy: 0.629214\n",
      "epoch: 223 - cost: 1.16075 -MSE: 32.0610805398 -Train Accuracy: 0.61236\n",
      "epoch: 224 - cost: 0.872009 -MSE: 29.3761523378 -Train Accuracy: 0.629214\n",
      "epoch: 225 - cost: 1.15295 -MSE: 32.0413768769 -Train Accuracy: 0.61236\n",
      "epoch: 226 - cost: 0.870472 -MSE: 29.3841912011 -Train Accuracy: 0.629214\n",
      "epoch: 227 - cost: 1.14523 -MSE: 32.0220873249 -Train Accuracy: 0.61236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 228 - cost: 0.868883 -MSE: 29.3920993463 -Train Accuracy: 0.629214\n",
      "epoch: 229 - cost: 1.13758 -MSE: 32.0032103295 -Train Accuracy: 0.61236\n",
      "epoch: 230 - cost: 0.867241 -MSE: 29.3998508802 -Train Accuracy: 0.629214\n",
      "epoch: 231 - cost: 1.12999 -MSE: 31.9846827493 -Train Accuracy: 0.61236\n",
      "epoch: 232 - cost: 0.865544 -MSE: 29.4074240154 -Train Accuracy: 0.629214\n",
      "epoch: 233 - cost: 1.12247 -MSE: 31.9664679896 -Train Accuracy: 0.61236\n",
      "epoch: 234 - cost: 0.863793 -MSE: 29.4148034593 -Train Accuracy: 0.629214\n",
      "epoch: 235 - cost: 1.115 -MSE: 31.9485381804 -Train Accuracy: 0.61236\n",
      "epoch: 236 - cost: 0.861985 -MSE: 29.4219704701 -Train Accuracy: 0.629214\n",
      "epoch: 237 - cost: 1.10759 -MSE: 31.9308403123 -Train Accuracy: 0.61236\n",
      "epoch: 238 - cost: 0.860123 -MSE: 29.428918967 -Train Accuracy: 0.629214\n",
      "epoch: 239 - cost: 1.10023 -MSE: 31.9133664597 -Train Accuracy: 0.61236\n",
      "epoch: 240 - cost: 0.858203 -MSE: 29.4356287859 -Train Accuracy: 0.629214\n",
      "epoch: 241 - cost: 1.09292 -MSE: 31.8960685673 -Train Accuracy: 0.61236\n",
      "epoch: 242 - cost: 0.856226 -MSE: 29.4420988306 -Train Accuracy: 0.629214\n",
      "epoch: 243 - cost: 1.08566 -MSE: 31.8789306771 -Train Accuracy: 0.61236\n",
      "epoch: 244 - cost: 0.854192 -MSE: 29.4483183547 -Train Accuracy: 0.629214\n",
      "epoch: 245 - cost: 1.07845 -MSE: 31.8619260981 -Train Accuracy: 0.61236\n",
      "epoch: 246 - cost: 0.8521 -MSE: 29.454285994 -Train Accuracy: 0.629214\n",
      "epoch: 247 - cost: 1.07127 -MSE: 31.8450374822 -Train Accuracy: 0.61236\n",
      "epoch: 248 - cost: 0.84995 -MSE: 29.4599950738 -Train Accuracy: 0.629214\n",
      "epoch: 249 - cost: 1.06413 -MSE: 31.8282427131 -Train Accuracy: 0.61236\n",
      "epoch: 250 - cost: 0.847742 -MSE: 29.4654379865 -Train Accuracy: 0.629214\n",
      "epoch: 251 - cost: 1.05703 -MSE: 31.8115231621 -Train Accuracy: 0.61236\n",
      "epoch: 252 - cost: 0.845474 -MSE: 29.4706224693 -Train Accuracy: 0.643258\n",
      "epoch: 253 - cost: 1.04996 -MSE: 31.7948679324 -Train Accuracy: 0.61236\n",
      "epoch: 254 - cost: 0.843148 -MSE: 29.475548882 -Train Accuracy: 0.643258\n",
      "epoch: 255 - cost: 1.04293 -MSE: 31.7782589054 -Train Accuracy: 0.61236\n",
      "epoch: 256 - cost: 0.840763 -MSE: 29.4802062845 -Train Accuracy: 0.643258\n",
      "epoch: 257 - cost: 1.03592 -MSE: 31.7616861893 -Train Accuracy: 0.61236\n",
      "epoch: 258 - cost: 0.838318 -MSE: 29.4846084196 -Train Accuracy: 0.643258\n",
      "epoch: 259 - cost: 1.02894 -MSE: 31.7451374108 -Train Accuracy: 0.61236\n",
      "epoch: 260 - cost: 0.835813 -MSE: 29.4887464329 -Train Accuracy: 0.643258\n",
      "epoch: 261 - cost: 1.02199 -MSE: 31.7286051483 -Train Accuracy: 0.61236\n",
      "epoch: 262 - cost: 0.83325 -MSE: 29.4926333546 -Train Accuracy: 0.643258\n",
      "epoch: 263 - cost: 1.01506 -MSE: 31.7120831396 -Train Accuracy: 0.61236\n",
      "epoch: 264 - cost: 0.830628 -MSE: 29.4962750575 -Train Accuracy: 0.643258\n",
      "epoch: 265 - cost: 1.00816 -MSE: 31.6955634732 -Train Accuracy: 0.61236\n",
      "epoch: 266 - cost: 0.827946 -MSE: 29.499669509 -Train Accuracy: 0.643258\n",
      "epoch: 267 - cost: 1.00127 -MSE: 31.6790383147 -Train Accuracy: 0.61236\n",
      "epoch: 268 - cost: 0.825206 -MSE: 29.5028319789 -Train Accuracy: 0.643258\n",
      "epoch: 269 - cost: 0.994414 -MSE: 31.6625125741 -Train Accuracy: 0.61236\n",
      "epoch: 270 - cost: 0.822406 -MSE: 29.5057670939 -Train Accuracy: 0.643258\n",
      "epoch: 271 - cost: 0.987574 -MSE: 31.6459740036 -Train Accuracy: 0.61236\n",
      "epoch: 272 - cost: 0.819549 -MSE: 29.5084830932 -Train Accuracy: 0.643258\n",
      "epoch: 273 - cost: 0.980756 -MSE: 31.629427581 -Train Accuracy: 0.61236\n",
      "epoch: 274 - cost: 0.816634 -MSE: 29.5109933175 -Train Accuracy: 0.643258\n",
      "epoch: 275 - cost: 0.973956 -MSE: 31.6128707971 -Train Accuracy: 0.61236\n",
      "epoch: 276 - cost: 0.813662 -MSE: 29.5133047656 -Train Accuracy: 0.643258\n",
      "epoch: 277 - cost: 0.967177 -MSE: 31.5963078934 -Train Accuracy: 0.61236\n",
      "epoch: 278 - cost: 0.810633 -MSE: 29.5154356635 -Train Accuracy: 0.651685\n",
      "epoch: 279 - cost: 0.960419 -MSE: 31.5797439416 -Train Accuracy: 0.61236\n",
      "epoch: 280 - cost: 0.807549 -MSE: 29.5173980663 -Train Accuracy: 0.651685\n",
      "epoch: 281 - cost: 0.953682 -MSE: 31.5631800416 -Train Accuracy: 0.61236\n",
      "epoch: 282 - cost: 0.80441 -MSE: 29.5192038356 -Train Accuracy: 0.651685\n",
      "epoch: 283 - cost: 0.946965 -MSE: 31.5466158682 -Train Accuracy: 0.61236\n",
      "epoch: 284 - cost: 0.801218 -MSE: 29.5208706753 -Train Accuracy: 0.65309\n",
      "epoch: 285 - cost: 0.940271 -MSE: 31.5300687788 -Train Accuracy: 0.61236\n",
      "epoch: 286 - cost: 0.797974 -MSE: 29.522411208 -Train Accuracy: 0.65309\n",
      "epoch: 287 - cost: 0.9336 -MSE: 31.5135362182 -Train Accuracy: 0.61236\n",
      "epoch: 288 - cost: 0.794679 -MSE: 29.5238391031 -Train Accuracy: 0.65309\n",
      "epoch: 289 - cost: 0.926954 -MSE: 31.4970305691 -Train Accuracy: 0.61236\n",
      "epoch: 290 - cost: 0.791335 -MSE: 29.5251762352 -Train Accuracy: 0.65309\n",
      "epoch: 291 - cost: 0.920334 -MSE: 31.4805617848 -Train Accuracy: 0.61236\n",
      "epoch: 292 - cost: 0.787943 -MSE: 29.5264350826 -Train Accuracy: 0.65309\n",
      "epoch: 293 - cost: 0.913743 -MSE: 31.4641326074 -Train Accuracy: 0.613764\n",
      "epoch: 294 - cost: 0.784507 -MSE: 29.527633729 -Train Accuracy: 0.654494\n",
      "epoch: 295 - cost: 0.907181 -MSE: 31.4477578529 -Train Accuracy: 0.613764\n",
      "epoch: 296 - cost: 0.781027 -MSE: 29.5287834854 -Train Accuracy: 0.667135\n",
      "epoch: 297 - cost: 0.900652 -MSE: 31.4314522511 -Train Accuracy: 0.613764\n",
      "epoch: 298 - cost: 0.777505 -MSE: 29.5299006585 -Train Accuracy: 0.667135\n",
      "epoch: 299 - cost: 0.894157 -MSE: 31.4152143314 -Train Accuracy: 0.623595\n",
      "epoch: 300 - cost: 0.773946 -MSE: 29.5310026439 -Train Accuracy: 0.668539\n",
      "epoch: 301 - cost: 0.887699 -MSE: 31.3990639695 -Train Accuracy: 0.634831\n",
      "epoch: 302 - cost: 0.770351 -MSE: 29.5320993602 -Train Accuracy: 0.668539\n",
      "epoch: 303 - cost: 0.88128 -MSE: 31.3830105091 -Train Accuracy: 0.636236\n",
      "epoch: 304 - cost: 0.766723 -MSE: 29.5332064204 -Train Accuracy: 0.671348\n",
      "epoch: 305 - cost: 0.874904 -MSE: 31.3670655721 -Train Accuracy: 0.63764\n",
      "epoch: 306 - cost: 0.763066 -MSE: 29.534337113 -Train Accuracy: 0.671348\n",
      "epoch: 307 - cost: 0.868572 -MSE: 31.3512440201 -Train Accuracy: 0.63764\n",
      "epoch: 308 - cost: 0.759382 -MSE: 29.535500443 -Train Accuracy: 0.669944\n",
      "epoch: 309 - cost: 0.862289 -MSE: 31.3355538457 -Train Accuracy: 0.641854\n",
      "epoch: 310 - cost: 0.755676 -MSE: 29.5367048291 -Train Accuracy: 0.669944\n",
      "epoch: 311 - cost: 0.856055 -MSE: 31.320007364 -Train Accuracy: 0.644663\n",
      "epoch: 312 - cost: 0.75195 -MSE: 29.5379646818 -Train Accuracy: 0.669944\n",
      "epoch: 313 - cost: 0.849875 -MSE: 31.3046140714 -Train Accuracy: 0.650281\n",
      "epoch: 314 - cost: 0.748207 -MSE: 29.5392861879 -Train Accuracy: 0.669944\n",
      "epoch: 315 - cost: 0.843751 -MSE: 31.2893831138 -Train Accuracy: 0.662921\n",
      "epoch: 316 - cost: 0.744453 -MSE: 29.5406736498 -Train Accuracy: 0.669944\n",
      "epoch: 317 - cost: 0.837686 -MSE: 31.2743305747 -Train Accuracy: 0.662921\n",
      "epoch: 318 - cost: 0.740689 -MSE: 29.5421376943 -Train Accuracy: 0.669944\n",
      "epoch: 319 - cost: 0.831683 -MSE: 31.2594648024 -Train Accuracy: 0.662921\n",
      "epoch: 320 - cost: 0.736922 -MSE: 29.5436815551 -Train Accuracy: 0.669944\n",
      "epoch: 321 - cost: 0.825744 -MSE: 31.2447915577 -Train Accuracy: 0.66573\n",
      "epoch: 322 - cost: 0.733153 -MSE: 29.5453101201 -Train Accuracy: 0.669944\n",
      "epoch: 323 - cost: 0.819872 -MSE: 31.2303234556 -Train Accuracy: 0.671348\n",
      "epoch: 324 - cost: 0.729386 -MSE: 29.5470277302 -Train Accuracy: 0.669944\n",
      "epoch: 325 - cost: 0.814068 -MSE: 31.2160690011 -Train Accuracy: 0.672753\n",
      "epoch: 326 - cost: 0.725626 -MSE: 29.5488350352 -Train Accuracy: 0.669944\n",
      "epoch: 327 - cost: 0.808337 -MSE: 31.2020355192 -Train Accuracy: 0.676966\n",
      "epoch: 328 - cost: 0.721876 -MSE: 29.5507370195 -Train Accuracy: 0.671348\n",
      "epoch: 329 - cost: 0.802678 -MSE: 31.1882299419 -Train Accuracy: 0.678371\n",
      "epoch: 330 - cost: 0.718139 -MSE: 29.5527367435 -Train Accuracy: 0.679775\n",
      "epoch: 331 - cost: 0.797096 -MSE: 31.1746638839 -Train Accuracy: 0.678371\n",
      "epoch: 332 - cost: 0.714418 -MSE: 29.5548355721 -Train Accuracy: 0.679775\n",
      "epoch: 333 - cost: 0.791592 -MSE: 31.1613412755 -Train Accuracy: 0.682584\n",
      "epoch: 334 - cost: 0.710718 -MSE: 29.5570326101 -Train Accuracy: 0.679775\n",
      "epoch: 335 - cost: 0.786167 -MSE: 31.1482650086 -Train Accuracy: 0.683989\n",
      "epoch: 336 - cost: 0.707041 -MSE: 29.5593273013 -Train Accuracy: 0.679775\n",
      "epoch: 337 - cost: 0.780823 -MSE: 31.1354454929 -Train Accuracy: 0.692416\n",
      "epoch: 338 - cost: 0.70339 -MSE: 29.5617225735 -Train Accuracy: 0.679775\n",
      "epoch: 339 - cost: 0.775562 -MSE: 31.1228816571 -Train Accuracy: 0.699438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 340 - cost: 0.699768 -MSE: 29.564210842 -Train Accuracy: 0.679775\n",
      "epoch: 341 - cost: 0.770383 -MSE: 31.1105826609 -Train Accuracy: 0.70927\n",
      "epoch: 342 - cost: 0.696178 -MSE: 29.5668029036 -Train Accuracy: 0.679775\n",
      "epoch: 343 - cost: 0.765291 -MSE: 31.098555161 -Train Accuracy: 0.70927\n",
      "epoch: 344 - cost: 0.692623 -MSE: 29.5694893645 -Train Accuracy: 0.679775\n",
      "epoch: 345 - cost: 0.760284 -MSE: 31.0868009989 -Train Accuracy: 0.710674\n",
      "epoch: 346 - cost: 0.689104 -MSE: 29.5722801999 -Train Accuracy: 0.679775\n",
      "epoch: 347 - cost: 0.755364 -MSE: 31.0753244687 -Train Accuracy: 0.712079\n",
      "epoch: 348 - cost: 0.685624 -MSE: 29.5751624551 -Train Accuracy: 0.68118\n",
      "epoch: 349 - cost: 0.750531 -MSE: 31.0641312981 -Train Accuracy: 0.712079\n",
      "epoch: 350 - cost: 0.682185 -MSE: 29.5781383969 -Train Accuracy: 0.68118\n",
      "epoch: 351 - cost: 0.745786 -MSE: 31.0532169273 -Train Accuracy: 0.716292\n",
      "epoch: 352 - cost: 0.678788 -MSE: 29.5812136699 -Train Accuracy: 0.685393\n",
      "epoch: 353 - cost: 0.74113 -MSE: 31.0425871117 -Train Accuracy: 0.716292\n",
      "epoch: 354 - cost: 0.675436 -MSE: 29.5843798011 -Train Accuracy: 0.685393\n",
      "epoch: 355 - cost: 0.736562 -MSE: 31.0322437673 -Train Accuracy: 0.717697\n",
      "epoch: 356 - cost: 0.672131 -MSE: 29.5876404797 -Train Accuracy: 0.685393\n",
      "epoch: 357 - cost: 0.732083 -MSE: 31.0221932856 -Train Accuracy: 0.720506\n",
      "epoch: 358 - cost: 0.668872 -MSE: 29.590990524 -Train Accuracy: 0.686798\n",
      "epoch: 359 - cost: 0.727692 -MSE: 31.0124335279 -Train Accuracy: 0.720506\n",
      "epoch: 360 - cost: 0.665663 -MSE: 29.5944323322 -Train Accuracy: 0.691011\n",
      "epoch: 361 - cost: 0.72339 -MSE: 31.0029666187 -Train Accuracy: 0.72191\n",
      "epoch: 362 - cost: 0.662504 -MSE: 29.5979667433 -Train Accuracy: 0.691011\n",
      "epoch: 363 - cost: 0.719176 -MSE: 30.9937893846 -Train Accuracy: 0.720506\n",
      "epoch: 364 - cost: 0.659394 -MSE: 29.6015824268 -Train Accuracy: 0.691011\n",
      "epoch: 365 - cost: 0.715049 -MSE: 30.9849059262 -Train Accuracy: 0.720506\n",
      "epoch: 366 - cost: 0.656336 -MSE: 29.6052895293 -Train Accuracy: 0.692416\n",
      "epoch: 367 - cost: 0.71101 -MSE: 30.9763165803 -Train Accuracy: 0.720506\n",
      "epoch: 368 - cost: 0.65333 -MSE: 29.6090822841 -Train Accuracy: 0.692416\n",
      "epoch: 369 - cost: 0.707057 -MSE: 30.9680174506 -Train Accuracy: 0.72191\n",
      "epoch: 370 - cost: 0.650376 -MSE: 29.6129608862 -Train Accuracy: 0.692416\n",
      "epoch: 371 - cost: 0.703189 -MSE: 30.9600127164 -Train Accuracy: 0.72191\n",
      "epoch: 372 - cost: 0.647476 -MSE: 29.6169208208 -Train Accuracy: 0.692416\n",
      "epoch: 373 - cost: 0.699406 -MSE: 30.9522987752 -Train Accuracy: 0.724719\n",
      "epoch: 374 - cost: 0.644627 -MSE: 29.6209661406 -Train Accuracy: 0.696629\n",
      "epoch: 375 - cost: 0.695707 -MSE: 30.9448753811 -Train Accuracy: 0.723315\n",
      "epoch: 376 - cost: 0.641833 -MSE: 29.6250914198 -Train Accuracy: 0.699438\n",
      "epoch: 377 - cost: 0.69209 -MSE: 30.9377362517 -Train Accuracy: 0.723315\n",
      "epoch: 378 - cost: 0.639091 -MSE: 29.6292913172 -Train Accuracy: 0.699438\n",
      "epoch: 379 - cost: 0.688555 -MSE: 30.9308830533 -Train Accuracy: 0.730337\n",
      "epoch: 380 - cost: 0.636402 -MSE: 29.633570423 -Train Accuracy: 0.70927\n",
      "epoch: 381 - cost: 0.6851 -MSE: 30.9243103994 -Train Accuracy: 0.730337\n",
      "epoch: 382 - cost: 0.633765 -MSE: 29.6379236641 -Train Accuracy: 0.714888\n",
      "epoch: 383 - cost: 0.681724 -MSE: 30.9180155154 -Train Accuracy: 0.730337\n",
      "epoch: 384 - cost: 0.631181 -MSE: 29.6423552287 -Train Accuracy: 0.714888\n",
      "epoch: 385 - cost: 0.678425 -MSE: 30.9120019645 -Train Accuracy: 0.728933\n",
      "epoch: 386 - cost: 0.628648 -MSE: 29.6468553027 -Train Accuracy: 0.716292\n",
      "epoch: 387 - cost: 0.675203 -MSE: 30.9062568319 -Train Accuracy: 0.731742\n",
      "epoch: 388 - cost: 0.626167 -MSE: 29.6514250338 -Train Accuracy: 0.716292\n",
      "epoch: 389 - cost: 0.672055 -MSE: 30.9007814093 -Train Accuracy: 0.734551\n",
      "epoch: 390 - cost: 0.623738 -MSE: 29.6560660981 -Train Accuracy: 0.716292\n",
      "epoch: 391 - cost: 0.66898 -MSE: 30.8955722878 -Train Accuracy: 0.735955\n",
      "epoch: 392 - cost: 0.621357 -MSE: 29.6607730639 -Train Accuracy: 0.716292\n",
      "epoch: 393 - cost: 0.665977 -MSE: 30.8906201503 -Train Accuracy: 0.73736\n",
      "epoch: 394 - cost: 0.619027 -MSE: 29.6655432213 -Train Accuracy: 0.716292\n",
      "epoch: 395 - cost: 0.663043 -MSE: 30.8859316014 -Train Accuracy: 0.738764\n",
      "epoch: 396 - cost: 0.616745 -MSE: 29.6703776299 -Train Accuracy: 0.716292\n",
      "epoch: 397 - cost: 0.660179 -MSE: 30.8814881549 -Train Accuracy: 0.738764\n",
      "epoch: 398 - cost: 0.614511 -MSE: 29.6752698975 -Train Accuracy: 0.716292\n",
      "epoch: 399 - cost: 0.657381 -MSE: 30.8772939227 -Train Accuracy: 0.740169\n",
      "epoch: 400 - cost: 0.612324 -MSE: 29.6802203807 -Train Accuracy: 0.716292\n",
      "epoch: 401 - cost: 0.654648 -MSE: 30.8733425235 -Train Accuracy: 0.740169\n",
      "epoch: 402 - cost: 0.610183 -MSE: 29.6852294596 -Train Accuracy: 0.719101\n",
      "epoch: 403 - cost: 0.651979 -MSE: 30.8696219561 -Train Accuracy: 0.740169\n",
      "epoch: 404 - cost: 0.608089 -MSE: 29.6902851278 -Train Accuracy: 0.719101\n",
      "epoch: 405 - cost: 0.649371 -MSE: 30.866137289 -Train Accuracy: 0.740169\n",
      "epoch: 406 - cost: 0.606038 -MSE: 29.6953988225 -Train Accuracy: 0.719101\n",
      "epoch: 407 - cost: 0.646825 -MSE: 30.8628804846 -Train Accuracy: 0.740169\n",
      "epoch: 408 - cost: 0.604031 -MSE: 29.7005607979 -Train Accuracy: 0.719101\n",
      "epoch: 409 - cost: 0.644337 -MSE: 30.8598434197 -Train Accuracy: 0.740169\n",
      "epoch: 410 - cost: 0.602067 -MSE: 29.705768551 -Train Accuracy: 0.720506\n",
      "epoch: 411 - cost: 0.641906 -MSE: 30.8570230033 -Train Accuracy: 0.745786\n",
      "epoch: 412 - cost: 0.600144 -MSE: 29.711021369 -Train Accuracy: 0.720506\n",
      "epoch: 413 - cost: 0.639532 -MSE: 30.8544144113 -Train Accuracy: 0.745786\n",
      "epoch: 414 - cost: 0.598263 -MSE: 29.7163194941 -Train Accuracy: 0.720506\n",
      "epoch: 415 - cost: 0.637212 -MSE: 30.8520114148 -Train Accuracy: 0.748595\n",
      "epoch: 416 - cost: 0.596421 -MSE: 29.7216569159 -Train Accuracy: 0.720506\n",
      "epoch: 417 - cost: 0.634944 -MSE: 30.8498075519 -Train Accuracy: 0.748595\n",
      "epoch: 418 - cost: 0.594618 -MSE: 29.7270305211 -Train Accuracy: 0.720506\n",
      "epoch: 419 - cost: 0.632727 -MSE: 30.8478043932 -Train Accuracy: 0.748595\n",
      "epoch: 420 - cost: 0.592854 -MSE: 29.7324492605 -Train Accuracy: 0.72191\n",
      "epoch: 421 - cost: 0.630561 -MSE: 30.8459889266 -Train Accuracy: 0.748595\n",
      "epoch: 422 - cost: 0.591126 -MSE: 29.7378987471 -Train Accuracy: 0.72191\n",
      "epoch: 423 - cost: 0.628443 -MSE: 30.8443621508 -Train Accuracy: 0.748595\n",
      "epoch: 424 - cost: 0.589435 -MSE: 29.7433766745 -Train Accuracy: 0.72191\n",
      "epoch: 425 - cost: 0.626373 -MSE: 30.8429152961 -Train Accuracy: 0.748595\n",
      "epoch: 426 - cost: 0.587779 -MSE: 29.748888333 -Train Accuracy: 0.72191\n",
      "epoch: 427 - cost: 0.624347 -MSE: 30.8416419725 -Train Accuracy: 0.754214\n",
      "epoch: 428 - cost: 0.586157 -MSE: 29.7544283395 -Train Accuracy: 0.72191\n",
      "epoch: 429 - cost: 0.622367 -MSE: 30.8405381367 -Train Accuracy: 0.754214\n",
      "epoch: 430 - cost: 0.584569 -MSE: 29.7599975396 -Train Accuracy: 0.72191\n",
      "epoch: 431 - cost: 0.620429 -MSE: 30.8396006058 -Train Accuracy: 0.754214\n",
      "epoch: 432 - cost: 0.583013 -MSE: 29.7655856942 -Train Accuracy: 0.72191\n",
      "epoch: 433 - cost: 0.618534 -MSE: 30.8388265441 -Train Accuracy: 0.755618\n",
      "epoch: 434 - cost: 0.58149 -MSE: 29.7712018992 -Train Accuracy: 0.723315\n",
      "epoch: 435 - cost: 0.61668 -MSE: 30.8382094863 -Train Accuracy: 0.757023\n",
      "epoch: 436 - cost: 0.579997 -MSE: 29.7768361074 -Train Accuracy: 0.723315\n",
      "epoch: 437 - cost: 0.614865 -MSE: 30.8377413258 -Train Accuracy: 0.757023\n",
      "epoch: 438 - cost: 0.578535 -MSE: 29.7824847154 -Train Accuracy: 0.723315\n",
      "epoch: 439 - cost: 0.613089 -MSE: 30.8374197086 -Train Accuracy: 0.757023\n",
      "epoch: 440 - cost: 0.577102 -MSE: 29.7881565206 -Train Accuracy: 0.727528\n",
      "epoch: 441 - cost: 0.611351 -MSE: 30.837242778 -Train Accuracy: 0.757023\n",
      "epoch: 442 - cost: 0.575698 -MSE: 29.7938418351 -Train Accuracy: 0.730337\n",
      "epoch: 443 - cost: 0.609649 -MSE: 30.8372038329 -Train Accuracy: 0.757023\n",
      "epoch: 444 - cost: 0.574322 -MSE: 29.7995385243 -Train Accuracy: 0.730337\n",
      "epoch: 445 - cost: 0.607982 -MSE: 30.8372939896 -Train Accuracy: 0.758427\n",
      "epoch: 446 - cost: 0.572973 -MSE: 29.8052468885 -Train Accuracy: 0.730337\n",
      "epoch: 447 - cost: 0.60635 -MSE: 30.8375153778 -Train Accuracy: 0.758427\n",
      "epoch: 448 - cost: 0.57165 -MSE: 29.8109619846 -Train Accuracy: 0.730337\n",
      "epoch: 449 - cost: 0.604751 -MSE: 30.8378626905 -Train Accuracy: 0.758427\n",
      "epoch: 450 - cost: 0.570354 -MSE: 29.8166876245 -Train Accuracy: 0.73736\n",
      "epoch: 451 - cost: 0.603184 -MSE: 30.8383291667 -Train Accuracy: 0.758427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 452 - cost: 0.569082 -MSE: 29.8224150282 -Train Accuracy: 0.73736\n",
      "epoch: 453 - cost: 0.60165 -MSE: 30.8389119389 -Train Accuracy: 0.758427\n",
      "epoch: 454 - cost: 0.567836 -MSE: 29.8281480476 -Train Accuracy: 0.73736\n",
      "epoch: 455 - cost: 0.600146 -MSE: 30.8396080339 -Train Accuracy: 0.758427\n",
      "epoch: 456 - cost: 0.566612 -MSE: 29.8338819706 -Train Accuracy: 0.73736\n",
      "epoch: 457 - cost: 0.598672 -MSE: 30.8404117433 -Train Accuracy: 0.758427\n",
      "epoch: 458 - cost: 0.565412 -MSE: 29.8396170913 -Train Accuracy: 0.73736\n",
      "epoch: 459 - cost: 0.597227 -MSE: 30.8413156359 -Train Accuracy: 0.758427\n",
      "epoch: 460 - cost: 0.564235 -MSE: 29.8453483921 -Train Accuracy: 0.73736\n",
      "epoch: 461 - cost: 0.59581 -MSE: 30.8423210319 -Train Accuracy: 0.758427\n",
      "epoch: 462 - cost: 0.563079 -MSE: 29.8510787464 -Train Accuracy: 0.73736\n",
      "epoch: 463 - cost: 0.59442 -MSE: 30.8434227863 -Train Accuracy: 0.758427\n",
      "epoch: 464 - cost: 0.561945 -MSE: 29.8567992348 -Train Accuracy: 0.738764\n",
      "epoch: 465 - cost: 0.593057 -MSE: 30.8446105376 -Train Accuracy: 0.758427\n",
      "epoch: 466 - cost: 0.560831 -MSE: 29.8625167652 -Train Accuracy: 0.738764\n",
      "epoch: 467 - cost: 0.59172 -MSE: 30.8458956097 -Train Accuracy: 0.758427\n",
      "epoch: 468 - cost: 0.559738 -MSE: 29.868225278 -Train Accuracy: 0.738764\n",
      "epoch: 469 - cost: 0.590408 -MSE: 30.8472570477 -Train Accuracy: 0.758427\n",
      "epoch: 470 - cost: 0.558665 -MSE: 29.8739250894 -Train Accuracy: 0.740169\n",
      "epoch: 471 - cost: 0.589121 -MSE: 30.8486993992 -Train Accuracy: 0.758427\n",
      "epoch: 472 - cost: 0.55761 -MSE: 29.879604759 -Train Accuracy: 0.741573\n",
      "epoch: 473 - cost: 0.587857 -MSE: 30.850213791 -Train Accuracy: 0.758427\n",
      "epoch: 474 - cost: 0.556574 -MSE: 29.885273306 -Train Accuracy: 0.741573\n",
      "epoch: 475 - cost: 0.586617 -MSE: 30.8518032851 -Train Accuracy: 0.758427\n",
      "epoch: 476 - cost: 0.555557 -MSE: 29.8909299149 -Train Accuracy: 0.741573\n",
      "epoch: 477 - cost: 0.585399 -MSE: 30.8534610061 -Train Accuracy: 0.758427\n",
      "epoch: 478 - cost: 0.554556 -MSE: 29.8965640283 -Train Accuracy: 0.741573\n",
      "epoch: 479 - cost: 0.584202 -MSE: 30.8551809673 -Train Accuracy: 0.758427\n",
      "epoch: 480 - cost: 0.553573 -MSE: 29.9021827943 -Train Accuracy: 0.741573\n",
      "epoch: 481 - cost: 0.583027 -MSE: 30.8569604205 -Train Accuracy: 0.758427\n",
      "epoch: 482 - cost: 0.552606 -MSE: 29.9077781385 -Train Accuracy: 0.741573\n",
      "epoch: 483 - cost: 0.581872 -MSE: 30.8587968004 -Train Accuracy: 0.758427\n",
      "epoch: 484 - cost: 0.551656 -MSE: 29.9133516184 -Train Accuracy: 0.741573\n",
      "epoch: 485 - cost: 0.580737 -MSE: 30.8606893123 -Train Accuracy: 0.758427\n",
      "epoch: 486 - cost: 0.550721 -MSE: 29.9189034858 -Train Accuracy: 0.741573\n",
      "epoch: 487 - cost: 0.579622 -MSE: 30.8626300685 -Train Accuracy: 0.758427\n",
      "epoch: 488 - cost: 0.549801 -MSE: 29.9244276216 -Train Accuracy: 0.741573\n",
      "epoch: 489 - cost: 0.578525 -MSE: 30.8646160992 -Train Accuracy: 0.758427\n",
      "epoch: 490 - cost: 0.548896 -MSE: 29.9299272587 -Train Accuracy: 0.741573\n",
      "epoch: 491 - cost: 0.577447 -MSE: 30.8666455208 -Train Accuracy: 0.769663\n",
      "epoch: 492 - cost: 0.548006 -MSE: 29.9353946362 -Train Accuracy: 0.747191\n",
      "epoch: 493 - cost: 0.576386 -MSE: 30.868715378 -Train Accuracy: 0.769663\n",
      "epoch: 494 - cost: 0.547129 -MSE: 29.9408381349 -Train Accuracy: 0.747191\n",
      "epoch: 495 - cost: 0.575343 -MSE: 30.8708195154 -Train Accuracy: 0.769663\n",
      "epoch: 496 - cost: 0.546266 -MSE: 29.9462457726 -Train Accuracy: 0.747191\n",
      "epoch: 497 - cost: 0.574316 -MSE: 30.8729572743 -Train Accuracy: 0.769663\n",
      "epoch: 498 - cost: 0.545416 -MSE: 29.9516226702 -Train Accuracy: 0.747191\n",
      "epoch: 499 - cost: 0.573305 -MSE: 30.8751235123 -Train Accuracy: 0.776685\n",
      "epoch: 500 - cost: 0.544579 -MSE: 29.9569677246 -Train Accuracy: 0.748595\n",
      "epoch: 501 - cost: 0.57231 -MSE: 30.8773177128 -Train Accuracy: 0.776685\n",
      "epoch: 502 - cost: 0.543754 -MSE: 29.9622789803 -Train Accuracy: 0.748595\n",
      "epoch: 503 - cost: 0.57133 -MSE: 30.879534793 -Train Accuracy: 0.776685\n",
      "epoch: 504 - cost: 0.542941 -MSE: 29.9675520772 -Train Accuracy: 0.745786\n",
      "epoch: 505 - cost: 0.570365 -MSE: 30.8817710289 -Train Accuracy: 0.776685\n",
      "epoch: 506 - cost: 0.54214 -MSE: 29.9727837966 -Train Accuracy: 0.748595\n",
      "epoch: 507 - cost: 0.569415 -MSE: 30.8840247424 -Train Accuracy: 0.77809\n",
      "epoch: 508 - cost: 0.54135 -MSE: 29.9779826507 -Train Accuracy: 0.748595\n",
      "epoch: 509 - cost: 0.568478 -MSE: 30.8862918707 -Train Accuracy: 0.77809\n",
      "epoch: 510 - cost: 0.540571 -MSE: 29.9831418688 -Train Accuracy: 0.748595\n",
      "epoch: 511 - cost: 0.567554 -MSE: 30.8885725091 -Train Accuracy: 0.77809\n",
      "epoch: 512 - cost: 0.539802 -MSE: 29.9882577897 -Train Accuracy: 0.748595\n",
      "epoch: 513 - cost: 0.566643 -MSE: 30.8908600814 -Train Accuracy: 0.77809\n",
      "epoch: 514 - cost: 0.539044 -MSE: 29.9933297346 -Train Accuracy: 0.751405\n",
      "epoch: 515 - cost: 0.565745 -MSE: 30.8931549653 -Train Accuracy: 0.77809\n",
      "epoch: 516 - cost: 0.538295 -MSE: 29.9983608293 -Train Accuracy: 0.751405\n",
      "epoch: 517 - cost: 0.56486 -MSE: 30.8954518677 -Train Accuracy: 0.77809\n",
      "epoch: 518 - cost: 0.537557 -MSE: 30.003350361 -Train Accuracy: 0.752809\n",
      "epoch: 519 - cost: 0.563986 -MSE: 30.8977494068 -Train Accuracy: 0.77809\n",
      "epoch: 520 - cost: 0.536827 -MSE: 30.0082948209 -Train Accuracy: 0.752809\n",
      "epoch: 521 - cost: 0.563123 -MSE: 30.9000484498 -Train Accuracy: 0.77809\n",
      "epoch: 522 - cost: 0.536107 -MSE: 30.0131927858 -Train Accuracy: 0.752809\n",
      "epoch: 523 - cost: 0.562271 -MSE: 30.9023428309 -Train Accuracy: 0.77809\n",
      "epoch: 524 - cost: 0.535395 -MSE: 30.0180464952 -Train Accuracy: 0.752809\n",
      "epoch: 525 - cost: 0.561431 -MSE: 30.9046302067 -Train Accuracy: 0.77809\n",
      "epoch: 526 - cost: 0.534692 -MSE: 30.022850039 -Train Accuracy: 0.752809\n",
      "epoch: 527 - cost: 0.5606 -MSE: 30.9069020745 -Train Accuracy: 0.77809\n",
      "epoch: 528 - cost: 0.533997 -MSE: 30.0276071703 -Train Accuracy: 0.752809\n",
      "epoch: 529 - cost: 0.55978 -MSE: 30.9091694249 -Train Accuracy: 0.77809\n",
      "epoch: 530 - cost: 0.53331 -MSE: 30.0323123355 -Train Accuracy: 0.752809\n",
      "epoch: 531 - cost: 0.558969 -MSE: 30.9114205785 -Train Accuracy: 0.77809\n",
      "epoch: 532 - cost: 0.532631 -MSE: 30.0369722267 -Train Accuracy: 0.752809\n",
      "epoch: 533 - cost: 0.558167 -MSE: 30.9136595471 -Train Accuracy: 0.77809\n",
      "epoch: 534 - cost: 0.531959 -MSE: 30.0415786264 -Train Accuracy: 0.754214\n",
      "epoch: 535 - cost: 0.557375 -MSE: 30.9158761828 -Train Accuracy: 0.77809\n",
      "epoch: 536 - cost: 0.531294 -MSE: 30.0461359232 -Train Accuracy: 0.754214\n",
      "epoch: 537 - cost: 0.556591 -MSE: 30.9180795095 -Train Accuracy: 0.77809\n",
      "epoch: 538 - cost: 0.530637 -MSE: 30.0506429387 -Train Accuracy: 0.754214\n",
      "epoch: 539 - cost: 0.555816 -MSE: 30.9202606007 -Train Accuracy: 0.77809\n",
      "epoch: 540 - cost: 0.529985 -MSE: 30.055097718 -Train Accuracy: 0.754214\n",
      "epoch: 541 - cost: 0.555049 -MSE: 30.9224158342 -Train Accuracy: 0.77809\n",
      "epoch: 542 - cost: 0.529341 -MSE: 30.0594959821 -Train Accuracy: 0.754214\n",
      "epoch: 543 - cost: 0.55429 -MSE: 30.9245443911 -Train Accuracy: 0.77809\n",
      "epoch: 544 - cost: 0.528703 -MSE: 30.0638451663 -Train Accuracy: 0.754214\n",
      "epoch: 545 - cost: 0.553539 -MSE: 30.9266482837 -Train Accuracy: 0.77809\n",
      "epoch: 546 - cost: 0.528071 -MSE: 30.0681385848 -Train Accuracy: 0.755618\n",
      "epoch: 547 - cost: 0.552795 -MSE: 30.9287246237 -Train Accuracy: 0.77809\n",
      "epoch: 548 - cost: 0.527445 -MSE: 30.072380059 -Train Accuracy: 0.757023\n",
      "epoch: 549 - cost: 0.552059 -MSE: 30.9307725724 -Train Accuracy: 0.77809\n",
      "epoch: 550 - cost: 0.526824 -MSE: 30.0765666883 -Train Accuracy: 0.757023\n",
      "epoch: 551 - cost: 0.551328 -MSE: 30.9327895851 -Train Accuracy: 0.77809\n",
      "epoch: 552 - cost: 0.526209 -MSE: 30.0807001332 -Train Accuracy: 0.757023\n",
      "epoch: 553 - cost: 0.550605 -MSE: 30.934771898 -Train Accuracy: 0.77809\n",
      "epoch: 554 - cost: 0.525599 -MSE: 30.0847780012 -Train Accuracy: 0.757023\n",
      "epoch: 555 - cost: 0.549889 -MSE: 30.9367213426 -Train Accuracy: 0.779494\n",
      "epoch: 556 - cost: 0.524995 -MSE: 30.0887986049 -Train Accuracy: 0.757023\n",
      "epoch: 557 - cost: 0.549179 -MSE: 30.9386405455 -Train Accuracy: 0.779494\n",
      "epoch: 558 - cost: 0.524396 -MSE: 30.0927676148 -Train Accuracy: 0.757023\n",
      "epoch: 559 - cost: 0.548474 -MSE: 30.9405195987 -Train Accuracy: 0.779494\n",
      "epoch: 560 - cost: 0.523802 -MSE: 30.0966814531 -Train Accuracy: 0.757023\n",
      "epoch: 561 - cost: 0.547776 -MSE: 30.9423637348 -Train Accuracy: 0.783708\n",
      "epoch: 562 - cost: 0.523212 -MSE: 30.1005380584 -Train Accuracy: 0.757023\n",
      "epoch: 563 - cost: 0.547084 -MSE: 30.9441706667 -Train Accuracy: 0.783708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 564 - cost: 0.522627 -MSE: 30.1043391714 -Train Accuracy: 0.757023\n",
      "epoch: 565 - cost: 0.546397 -MSE: 30.9459311 -Train Accuracy: 0.783708\n",
      "epoch: 566 - cost: 0.522046 -MSE: 30.1080825904 -Train Accuracy: 0.757023\n",
      "epoch: 567 - cost: 0.545715 -MSE: 30.9476566752 -Train Accuracy: 0.783708\n",
      "epoch: 568 - cost: 0.52147 -MSE: 30.1117714152 -Train Accuracy: 0.757023\n",
      "epoch: 569 - cost: 0.545038 -MSE: 30.9493392468 -Train Accuracy: 0.783708\n",
      "epoch: 570 - cost: 0.520898 -MSE: 30.1154041836 -Train Accuracy: 0.759831\n",
      "epoch: 571 - cost: 0.544367 -MSE: 30.9509827607 -Train Accuracy: 0.783708\n",
      "epoch: 572 - cost: 0.520329 -MSE: 30.11898083 -Train Accuracy: 0.759831\n",
      "epoch: 573 - cost: 0.5437 -MSE: 30.952580172 -Train Accuracy: 0.783708\n",
      "epoch: 574 - cost: 0.519765 -MSE: 30.1224997903 -Train Accuracy: 0.759831\n",
      "epoch: 575 - cost: 0.543038 -MSE: 30.9541356464 -Train Accuracy: 0.783708\n",
      "epoch: 576 - cost: 0.519205 -MSE: 30.1259666747 -Train Accuracy: 0.759831\n",
      "epoch: 577 - cost: 0.542381 -MSE: 30.9556494588 -Train Accuracy: 0.783708\n",
      "epoch: 578 - cost: 0.518648 -MSE: 30.1293756226 -Train Accuracy: 0.759831\n",
      "epoch: 579 - cost: 0.541727 -MSE: 30.9571142556 -Train Accuracy: 0.783708\n",
      "epoch: 580 - cost: 0.518094 -MSE: 30.1327270988 -Train Accuracy: 0.76264\n",
      "epoch: 581 - cost: 0.541079 -MSE: 30.9585349433 -Train Accuracy: 0.783708\n",
      "epoch: 582 - cost: 0.517545 -MSE: 30.1360275551 -Train Accuracy: 0.76264\n",
      "epoch: 583 - cost: 0.540434 -MSE: 30.9599117293 -Train Accuracy: 0.783708\n",
      "epoch: 584 - cost: 0.516998 -MSE: 30.1392665493 -Train Accuracy: 0.76264\n",
      "epoch: 585 - cost: 0.539794 -MSE: 30.9612423872 -Train Accuracy: 0.786517\n",
      "epoch: 586 - cost: 0.516455 -MSE: 30.1424514999 -Train Accuracy: 0.76264\n",
      "epoch: 587 - cost: 0.539157 -MSE: 30.9625233084 -Train Accuracy: 0.786517\n",
      "epoch: 588 - cost: 0.515916 -MSE: 30.14558034 -Train Accuracy: 0.76264\n",
      "epoch: 589 - cost: 0.538525 -MSE: 30.9637630102 -Train Accuracy: 0.786517\n",
      "epoch: 590 - cost: 0.515379 -MSE: 30.1486569294 -Train Accuracy: 0.76264\n",
      "epoch: 591 - cost: 0.537896 -MSE: 30.9649514368 -Train Accuracy: 0.786517\n",
      "epoch: 592 - cost: 0.514845 -MSE: 30.151674733 -Train Accuracy: 0.76264\n",
      "epoch: 593 - cost: 0.537271 -MSE: 30.9660906972 -Train Accuracy: 0.786517\n",
      "epoch: 594 - cost: 0.514315 -MSE: 30.1546370291 -Train Accuracy: 0.764045\n",
      "epoch: 595 - cost: 0.536649 -MSE: 30.9671815867 -Train Accuracy: 0.786517\n",
      "epoch: 596 - cost: 0.513787 -MSE: 30.1575419197 -Train Accuracy: 0.764045\n",
      "epoch: 597 - cost: 0.536031 -MSE: 30.9682251363 -Train Accuracy: 0.786517\n",
      "epoch: 598 - cost: 0.513262 -MSE: 30.1603954303 -Train Accuracy: 0.764045\n",
      "epoch: 599 - cost: 0.535416 -MSE: 30.9692165231 -Train Accuracy: 0.786517\n",
      "epoch: 600 - cost: 0.51274 -MSE: 30.1631903908 -Train Accuracy: 0.764045\n",
      "epoch: 601 - cost: 0.534804 -MSE: 30.9701607446 -Train Accuracy: 0.786517\n",
      "epoch: 602 - cost: 0.512221 -MSE: 30.1659287015 -Train Accuracy: 0.764045\n",
      "epoch: 603 - cost: 0.534196 -MSE: 30.9710507928 -Train Accuracy: 0.786517\n",
      "epoch: 604 - cost: 0.511704 -MSE: 30.1686148628 -Train Accuracy: 0.764045\n",
      "epoch: 605 - cost: 0.53359 -MSE: 30.971895293 -Train Accuracy: 0.786517\n",
      "epoch: 606 - cost: 0.51119 -MSE: 30.171243156 -Train Accuracy: 0.764045\n",
      "epoch: 607 - cost: 0.532988 -MSE: 30.9726864623 -Train Accuracy: 0.79073\n",
      "epoch: 608 - cost: 0.510678 -MSE: 30.1738204057 -Train Accuracy: 0.764045\n",
      "epoch: 609 - cost: 0.532388 -MSE: 30.9734320036 -Train Accuracy: 0.79073\n",
      "epoch: 610 - cost: 0.510169 -MSE: 30.1763417591 -Train Accuracy: 0.768258\n",
      "epoch: 611 - cost: 0.531792 -MSE: 30.9741275317 -Train Accuracy: 0.79073\n",
      "epoch: 612 - cost: 0.509663 -MSE: 30.178811393 -Train Accuracy: 0.768258\n",
      "epoch: 613 - cost: 0.531199 -MSE: 30.9747708589 -Train Accuracy: 0.79073\n",
      "epoch: 614 - cost: 0.509158 -MSE: 30.1812230601 -Train Accuracy: 0.769663\n",
      "epoch: 615 - cost: 0.530608 -MSE: 30.9753621095 -Train Accuracy: 0.79073\n",
      "epoch: 616 - cost: 0.508657 -MSE: 30.1835828973 -Train Accuracy: 0.769663\n",
      "epoch: 617 - cost: 0.530021 -MSE: 30.975903609 -Train Accuracy: 0.79073\n",
      "epoch: 618 - cost: 0.508157 -MSE: 30.185885773 -Train Accuracy: 0.769663\n",
      "epoch: 619 - cost: 0.529436 -MSE: 30.9763975843 -Train Accuracy: 0.79073\n",
      "epoch: 620 - cost: 0.50766 -MSE: 30.1881362487 -Train Accuracy: 0.769663\n",
      "epoch: 621 - cost: 0.528853 -MSE: 30.9768347542 -Train Accuracy: 0.792135\n",
      "epoch: 622 - cost: 0.507165 -MSE: 30.1903303189 -Train Accuracy: 0.769663\n",
      "epoch: 623 - cost: 0.528273 -MSE: 30.9772186949 -Train Accuracy: 0.792135\n",
      "epoch: 624 - cost: 0.506672 -MSE: 30.1924711143 -Train Accuracy: 0.769663\n",
      "epoch: 625 - cost: 0.527696 -MSE: 30.9775572674 -Train Accuracy: 0.792135\n",
      "epoch: 626 - cost: 0.506182 -MSE: 30.1945573454 -Train Accuracy: 0.771067\n",
      "epoch: 627 - cost: 0.527121 -MSE: 30.9778415394 -Train Accuracy: 0.792135\n",
      "epoch: 628 - cost: 0.505693 -MSE: 30.1965911711 -Train Accuracy: 0.771067\n",
      "epoch: 629 - cost: 0.526549 -MSE: 30.9780720911 -Train Accuracy: 0.792135\n",
      "epoch: 630 - cost: 0.505207 -MSE: 30.1985710008 -Train Accuracy: 0.771067\n",
      "epoch: 631 - cost: 0.52598 -MSE: 30.978252501 -Train Accuracy: 0.793539\n",
      "epoch: 632 - cost: 0.504723 -MSE: 30.2004940229 -Train Accuracy: 0.771067\n",
      "epoch: 633 - cost: 0.525412 -MSE: 30.9783815913 -Train Accuracy: 0.793539\n",
      "epoch: 634 - cost: 0.504241 -MSE: 30.2023670482 -Train Accuracy: 0.771067\n",
      "epoch: 635 - cost: 0.524848 -MSE: 30.9784610814 -Train Accuracy: 0.793539\n",
      "epoch: 636 - cost: 0.503761 -MSE: 30.2041861924 -Train Accuracy: 0.771067\n",
      "epoch: 637 - cost: 0.524285 -MSE: 30.9784886657 -Train Accuracy: 0.796348\n",
      "epoch: 638 - cost: 0.503283 -MSE: 30.2059548118 -Train Accuracy: 0.771067\n",
      "epoch: 639 - cost: 0.523725 -MSE: 30.978464601 -Train Accuracy: 0.796348\n",
      "epoch: 640 - cost: 0.502807 -MSE: 30.2076653282 -Train Accuracy: 0.771067\n",
      "epoch: 641 - cost: 0.523167 -MSE: 30.9783870478 -Train Accuracy: 0.796348\n",
      "epoch: 642 - cost: 0.502333 -MSE: 30.2093215996 -Train Accuracy: 0.771067\n",
      "epoch: 643 - cost: 0.522612 -MSE: 30.9782582588 -Train Accuracy: 0.799157\n",
      "epoch: 644 - cost: 0.501861 -MSE: 30.2109272675 -Train Accuracy: 0.771067\n",
      "epoch: 645 - cost: 0.522059 -MSE: 30.9780782216 -Train Accuracy: 0.799157\n",
      "epoch: 646 - cost: 0.50139 -MSE: 30.2124821047 -Train Accuracy: 0.771067\n",
      "epoch: 647 - cost: 0.521508 -MSE: 30.9778455225 -Train Accuracy: 0.799157\n",
      "epoch: 648 - cost: 0.500922 -MSE: 30.2139789863 -Train Accuracy: 0.771067\n",
      "epoch: 649 - cost: 0.520959 -MSE: 30.977558617 -Train Accuracy: 0.801966\n",
      "epoch: 650 - cost: 0.500456 -MSE: 30.2154266296 -Train Accuracy: 0.771067\n",
      "epoch: 651 - cost: 0.520412 -MSE: 30.9772247891 -Train Accuracy: 0.801966\n",
      "epoch: 652 - cost: 0.499992 -MSE: 30.2168210339 -Train Accuracy: 0.772472\n",
      "epoch: 653 - cost: 0.519868 -MSE: 30.976838754 -Train Accuracy: 0.801966\n",
      "epoch: 654 - cost: 0.499529 -MSE: 30.2181605959 -Train Accuracy: 0.772472\n",
      "epoch: 655 - cost: 0.519326 -MSE: 30.9763995449 -Train Accuracy: 0.801966\n",
      "epoch: 656 - cost: 0.499069 -MSE: 30.2194513427 -Train Accuracy: 0.772472\n",
      "epoch: 657 - cost: 0.518786 -MSE: 30.9759122174 -Train Accuracy: 0.801966\n",
      "epoch: 658 - cost: 0.49861 -MSE: 30.2206850161 -Train Accuracy: 0.772472\n",
      "epoch: 659 - cost: 0.518248 -MSE: 30.9753705642 -Train Accuracy: 0.801966\n",
      "epoch: 660 - cost: 0.498153 -MSE: 30.2218744964 -Train Accuracy: 0.772472\n",
      "epoch: 661 - cost: 0.517713 -MSE: 30.9747808461 -Train Accuracy: 0.801966\n",
      "epoch: 662 - cost: 0.497699 -MSE: 30.2230057585 -Train Accuracy: 0.772472\n",
      "epoch: 663 - cost: 0.517179 -MSE: 30.9741390706 -Train Accuracy: 0.801966\n",
      "epoch: 664 - cost: 0.497246 -MSE: 30.2240871403 -Train Accuracy: 0.772472\n",
      "epoch: 665 - cost: 0.516648 -MSE: 30.973443508 -Train Accuracy: 0.801966\n",
      "epoch: 666 - cost: 0.496794 -MSE: 30.2251117438 -Train Accuracy: 0.772472\n",
      "epoch: 667 - cost: 0.516119 -MSE: 30.9726987913 -Train Accuracy: 0.801966\n",
      "epoch: 668 - cost: 0.496345 -MSE: 30.226087505 -Train Accuracy: 0.772472\n",
      "epoch: 669 - cost: 0.515592 -MSE: 30.9719035341 -Train Accuracy: 0.801966\n",
      "epoch: 670 - cost: 0.495898 -MSE: 30.2270063727 -Train Accuracy: 0.772472\n",
      "epoch: 671 - cost: 0.515067 -MSE: 30.9710557379 -Train Accuracy: 0.801966\n",
      "epoch: 672 - cost: 0.495452 -MSE: 30.2278781208 -Train Accuracy: 0.772472\n",
      "epoch: 673 - cost: 0.514544 -MSE: 30.9701552243 -Train Accuracy: 0.801966\n",
      "epoch: 674 - cost: 0.495008 -MSE: 30.228694908 -Train Accuracy: 0.772472\n",
      "epoch: 675 - cost: 0.514023 -MSE: 30.9692029598 -Train Accuracy: 0.801966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 676 - cost: 0.494565 -MSE: 30.2294542932 -Train Accuracy: 0.772472\n",
      "epoch: 677 - cost: 0.513504 -MSE: 30.9681996542 -Train Accuracy: 0.801966\n",
      "epoch: 678 - cost: 0.494125 -MSE: 30.2301695372 -Train Accuracy: 0.772472\n",
      "epoch: 679 - cost: 0.512987 -MSE: 30.9671490345 -Train Accuracy: 0.801966\n",
      "epoch: 680 - cost: 0.493687 -MSE: 30.230829037 -Train Accuracy: 0.772472\n",
      "epoch: 681 - cost: 0.512472 -MSE: 30.9660475172 -Train Accuracy: 0.801966\n",
      "epoch: 682 - cost: 0.49325 -MSE: 30.23144246 -Train Accuracy: 0.772472\n",
      "epoch: 683 - cost: 0.511959 -MSE: 30.9648954876 -Train Accuracy: 0.801966\n",
      "epoch: 684 - cost: 0.492815 -MSE: 30.2320012808 -Train Accuracy: 0.772472\n",
      "epoch: 685 - cost: 0.511449 -MSE: 30.9636941786 -Train Accuracy: 0.801966\n",
      "epoch: 686 - cost: 0.492381 -MSE: 30.2325069664 -Train Accuracy: 0.772472\n",
      "epoch: 687 - cost: 0.51094 -MSE: 30.9624407976 -Train Accuracy: 0.801966\n",
      "epoch: 688 - cost: 0.49195 -MSE: 30.232963508 -Train Accuracy: 0.776685\n",
      "epoch: 689 - cost: 0.510434 -MSE: 30.9611404551 -Train Accuracy: 0.801966\n",
      "epoch: 690 - cost: 0.49152 -MSE: 30.2333679664 -Train Accuracy: 0.782303\n",
      "epoch: 691 - cost: 0.509928 -MSE: 30.959788758 -Train Accuracy: 0.801966\n",
      "epoch: 692 - cost: 0.491092 -MSE: 30.2337241518 -Train Accuracy: 0.782303\n",
      "epoch: 693 - cost: 0.509426 -MSE: 30.9583894919 -Train Accuracy: 0.801966\n",
      "epoch: 694 - cost: 0.490666 -MSE: 30.2340296213 -Train Accuracy: 0.782303\n",
      "epoch: 695 - cost: 0.508925 -MSE: 30.9569408839 -Train Accuracy: 0.801966\n",
      "epoch: 696 - cost: 0.490241 -MSE: 30.2342842483 -Train Accuracy: 0.782303\n",
      "epoch: 697 - cost: 0.508427 -MSE: 30.9554391369 -Train Accuracy: 0.801966\n",
      "epoch: 698 - cost: 0.489818 -MSE: 30.234486694 -Train Accuracy: 0.782303\n",
      "epoch: 699 - cost: 0.50793 -MSE: 30.9538963064 -Train Accuracy: 0.801966\n",
      "epoch: 700 - cost: 0.489397 -MSE: 30.2346405322 -Train Accuracy: 0.782303\n",
      "epoch: 701 - cost: 0.507436 -MSE: 30.9523014236 -Train Accuracy: 0.801966\n",
      "epoch: 702 - cost: 0.488978 -MSE: 30.2347447768 -Train Accuracy: 0.782303\n",
      "epoch: 703 - cost: 0.506943 -MSE: 30.9506586649 -Train Accuracy: 0.801966\n",
      "epoch: 704 - cost: 0.48856 -MSE: 30.234796652 -Train Accuracy: 0.783708\n",
      "epoch: 705 - cost: 0.506452 -MSE: 30.9489674825 -Train Accuracy: 0.803371\n",
      "epoch: 706 - cost: 0.488144 -MSE: 30.2348042769 -Train Accuracy: 0.783708\n",
      "epoch: 707 - cost: 0.505963 -MSE: 30.9472354942 -Train Accuracy: 0.803371\n",
      "epoch: 708 - cost: 0.48773 -MSE: 30.2347603148 -Train Accuracy: 0.783708\n",
      "epoch: 709 - cost: 0.505477 -MSE: 30.9454491102 -Train Accuracy: 0.803371\n",
      "epoch: 710 - cost: 0.487317 -MSE: 30.2346691136 -Train Accuracy: 0.783708\n",
      "epoch: 711 - cost: 0.504992 -MSE: 30.9436234932 -Train Accuracy: 0.803371\n",
      "epoch: 712 - cost: 0.486906 -MSE: 30.2345314507 -Train Accuracy: 0.783708\n",
      "epoch: 713 - cost: 0.504509 -MSE: 30.9417482216 -Train Accuracy: 0.804775\n",
      "epoch: 714 - cost: 0.486497 -MSE: 30.234342695 -Train Accuracy: 0.783708\n",
      "epoch: 715 - cost: 0.504029 -MSE: 30.9398258199 -Train Accuracy: 0.807584\n",
      "epoch: 716 - cost: 0.48609 -MSE: 30.2341080185 -Train Accuracy: 0.786517\n",
      "epoch: 717 - cost: 0.50355 -MSE: 30.9378610779 -Train Accuracy: 0.807584\n",
      "epoch: 718 - cost: 0.485684 -MSE: 30.2338253666 -Train Accuracy: 0.786517\n",
      "epoch: 719 - cost: 0.503073 -MSE: 30.9358506959 -Train Accuracy: 0.807584\n",
      "epoch: 720 - cost: 0.48528 -MSE: 30.2334973757 -Train Accuracy: 0.786517\n",
      "epoch: 721 - cost: 0.502598 -MSE: 30.9337954866 -Train Accuracy: 0.807584\n",
      "epoch: 722 - cost: 0.484878 -MSE: 30.2331233117 -Train Accuracy: 0.786517\n",
      "epoch: 723 - cost: 0.502125 -MSE: 30.9316977944 -Train Accuracy: 0.807584\n",
      "epoch: 724 - cost: 0.484477 -MSE: 30.2327032159 -Train Accuracy: 0.786517\n",
      "epoch: 725 - cost: 0.501654 -MSE: 30.9295542739 -Train Accuracy: 0.807584\n",
      "epoch: 726 - cost: 0.484078 -MSE: 30.2322372422 -Train Accuracy: 0.786517\n",
      "epoch: 727 - cost: 0.501185 -MSE: 30.9273702966 -Train Accuracy: 0.807584\n",
      "epoch: 728 - cost: 0.48368 -MSE: 30.2317266855 -Train Accuracy: 0.786517\n",
      "epoch: 729 - cost: 0.500718 -MSE: 30.9251452629 -Train Accuracy: 0.810393\n",
      "epoch: 730 - cost: 0.483284 -MSE: 30.2311742667 -Train Accuracy: 0.786517\n",
      "epoch: 731 - cost: 0.500253 -MSE: 30.9228821791 -Train Accuracy: 0.810393\n",
      "epoch: 732 - cost: 0.48289 -MSE: 30.2305761121 -Train Accuracy: 0.786517\n",
      "epoch: 733 - cost: 0.499789 -MSE: 30.9205710343 -Train Accuracy: 0.810393\n",
      "epoch: 734 - cost: 0.482498 -MSE: 30.2299350817 -Train Accuracy: 0.787921\n",
      "epoch: 735 - cost: 0.499328 -MSE: 30.9182216869 -Train Accuracy: 0.810393\n",
      "epoch: 736 - cost: 0.482107 -MSE: 30.2292461782 -Train Accuracy: 0.787921\n",
      "epoch: 737 - cost: 0.498869 -MSE: 30.9158318123 -Train Accuracy: 0.810393\n",
      "epoch: 738 - cost: 0.481718 -MSE: 30.2285193482 -Train Accuracy: 0.787921\n",
      "epoch: 739 - cost: 0.498411 -MSE: 30.9134015045 -Train Accuracy: 0.810393\n",
      "epoch: 740 - cost: 0.48133 -MSE: 30.2277466102 -Train Accuracy: 0.787921\n",
      "epoch: 741 - cost: 0.497955 -MSE: 30.9109317569 -Train Accuracy: 0.810393\n",
      "epoch: 742 - cost: 0.480944 -MSE: 30.2269379703 -Train Accuracy: 0.787921\n",
      "epoch: 743 - cost: 0.497502 -MSE: 30.9084264386 -Train Accuracy: 0.810393\n",
      "epoch: 744 - cost: 0.48056 -MSE: 30.22608333 -Train Accuracy: 0.787921\n",
      "epoch: 745 - cost: 0.49705 -MSE: 30.9058839255 -Train Accuracy: 0.810393\n",
      "epoch: 746 - cost: 0.480177 -MSE: 30.2251933774 -Train Accuracy: 0.787921\n",
      "epoch: 747 - cost: 0.4966 -MSE: 30.903301908 -Train Accuracy: 0.810393\n",
      "epoch: 748 - cost: 0.479796 -MSE: 30.2242584603 -Train Accuracy: 0.787921\n",
      "epoch: 749 - cost: 0.496152 -MSE: 30.9006840826 -Train Accuracy: 0.810393\n",
      "epoch: 750 - cost: 0.479416 -MSE: 30.2232856488 -Train Accuracy: 0.787921\n",
      "epoch: 751 - cost: 0.495706 -MSE: 30.8980308635 -Train Accuracy: 0.810393\n",
      "epoch: 752 - cost: 0.479039 -MSE: 30.2222729223 -Train Accuracy: 0.789326\n",
      "epoch: 753 - cost: 0.495262 -MSE: 30.8953375165 -Train Accuracy: 0.810393\n",
      "epoch: 754 - cost: 0.478662 -MSE: 30.2212212189 -Train Accuracy: 0.789326\n",
      "epoch: 755 - cost: 0.49482 -MSE: 30.8926129285 -Train Accuracy: 0.810393\n",
      "epoch: 756 - cost: 0.478288 -MSE: 30.2201373055 -Train Accuracy: 0.787921\n",
      "epoch: 757 - cost: 0.494379 -MSE: 30.8898569221 -Train Accuracy: 0.810393\n",
      "epoch: 758 - cost: 0.477914 -MSE: 30.2190106826 -Train Accuracy: 0.787921\n",
      "epoch: 759 - cost: 0.493941 -MSE: 30.8870642618 -Train Accuracy: 0.810393\n",
      "epoch: 760 - cost: 0.477543 -MSE: 30.2178518872 -Train Accuracy: 0.789326\n",
      "epoch: 761 - cost: 0.493504 -MSE: 30.88423938 -Train Accuracy: 0.810393\n",
      "epoch: 762 - cost: 0.477173 -MSE: 30.2166542868 -Train Accuracy: 0.789326\n",
      "epoch: 763 - cost: 0.493069 -MSE: 30.8813832129 -Train Accuracy: 0.810393\n",
      "epoch: 764 - cost: 0.476805 -MSE: 30.2154218673 -Train Accuracy: 0.789326\n",
      "epoch: 765 - cost: 0.492637 -MSE: 30.8784940155 -Train Accuracy: 0.810393\n",
      "epoch: 766 - cost: 0.476438 -MSE: 30.2141562062 -Train Accuracy: 0.789326\n",
      "epoch: 767 - cost: 0.492205 -MSE: 30.8755724585 -Train Accuracy: 0.810393\n",
      "epoch: 768 - cost: 0.476073 -MSE: 30.2128536886 -Train Accuracy: 0.789326\n",
      "epoch: 769 - cost: 0.491776 -MSE: 30.8726224276 -Train Accuracy: 0.810393\n",
      "epoch: 770 - cost: 0.475709 -MSE: 30.2115195827 -Train Accuracy: 0.789326\n",
      "epoch: 771 - cost: 0.491349 -MSE: 30.8696428455 -Train Accuracy: 0.810393\n",
      "epoch: 772 - cost: 0.475347 -MSE: 30.2101538717 -Train Accuracy: 0.789326\n",
      "epoch: 773 - cost: 0.490923 -MSE: 30.8666340544 -Train Accuracy: 0.810393\n",
      "epoch: 774 - cost: 0.474986 -MSE: 30.2087520285 -Train Accuracy: 0.789326\n",
      "epoch: 775 - cost: 0.4905 -MSE: 30.8635958357 -Train Accuracy: 0.810393\n",
      "epoch: 776 - cost: 0.474628 -MSE: 30.2073200892 -Train Accuracy: 0.789326\n",
      "epoch: 777 - cost: 0.490078 -MSE: 30.8605305232 -Train Accuracy: 0.810393\n",
      "epoch: 778 - cost: 0.47427 -MSE: 30.2058561319 -Train Accuracy: 0.789326\n",
      "epoch: 779 - cost: 0.489658 -MSE: 30.8574361607 -Train Accuracy: 0.810393\n",
      "epoch: 780 - cost: 0.473914 -MSE: 30.2043636165 -Train Accuracy: 0.789326\n",
      "epoch: 781 - cost: 0.48924 -MSE: 30.8543174567 -Train Accuracy: 0.810393\n",
      "epoch: 782 - cost: 0.47356 -MSE: 30.2028387452 -Train Accuracy: 0.789326\n",
      "epoch: 783 - cost: 0.488823 -MSE: 30.8511718444 -Train Accuracy: 0.810393\n",
      "epoch: 784 - cost: 0.473207 -MSE: 30.2012837169 -Train Accuracy: 0.789326\n",
      "epoch: 785 - cost: 0.488409 -MSE: 30.8479973403 -Train Accuracy: 0.810393\n",
      "epoch: 786 - cost: 0.472856 -MSE: 30.1996968816 -Train Accuracy: 0.789326\n",
      "epoch: 787 - cost: 0.487996 -MSE: 30.8447974151 -Train Accuracy: 0.810393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 788 - cost: 0.472506 -MSE: 30.1980855744 -Train Accuracy: 0.789326\n",
      "epoch: 789 - cost: 0.487585 -MSE: 30.8415757668 -Train Accuracy: 0.810393\n",
      "epoch: 790 - cost: 0.472158 -MSE: 30.1964441685 -Train Accuracy: 0.789326\n",
      "epoch: 791 - cost: 0.487176 -MSE: 30.8383304998 -Train Accuracy: 0.810393\n",
      "epoch: 792 - cost: 0.471811 -MSE: 30.1947792829 -Train Accuracy: 0.789326\n",
      "epoch: 793 - cost: 0.486768 -MSE: 30.8350675824 -Train Accuracy: 0.810393\n",
      "epoch: 794 - cost: 0.471465 -MSE: 30.1930890564 -Train Accuracy: 0.792135\n",
      "epoch: 795 - cost: 0.486363 -MSE: 30.8317741091 -Train Accuracy: 0.810393\n",
      "epoch: 796 - cost: 0.471122 -MSE: 30.1913732444 -Train Accuracy: 0.792135\n",
      "epoch: 797 - cost: 0.485959 -MSE: 30.8284668335 -Train Accuracy: 0.810393\n",
      "epoch: 798 - cost: 0.47078 -MSE: 30.1896318417 -Train Accuracy: 0.792135\n",
      "epoch: 799 - cost: 0.485557 -MSE: 30.8251346569 -Train Accuracy: 0.810393\n",
      "epoch: 800 - cost: 0.470439 -MSE: 30.187865571 -Train Accuracy: 0.792135\n",
      "epoch: 801 - cost: 0.485156 -MSE: 30.8217846936 -Train Accuracy: 0.810393\n",
      "epoch: 802 - cost: 0.470099 -MSE: 30.1860736515 -Train Accuracy: 0.792135\n",
      "epoch: 803 - cost: 0.484758 -MSE: 30.818411412 -Train Accuracy: 0.810393\n",
      "epoch: 804 - cost: 0.469761 -MSE: 30.1842605812 -Train Accuracy: 0.792135\n",
      "epoch: 805 - cost: 0.484361 -MSE: 30.8150208828 -Train Accuracy: 0.810393\n",
      "epoch: 806 - cost: 0.469425 -MSE: 30.1824245268 -Train Accuracy: 0.792135\n",
      "epoch: 807 - cost: 0.483966 -MSE: 30.8116158948 -Train Accuracy: 0.810393\n",
      "epoch: 808 - cost: 0.46909 -MSE: 30.1805668211 -Train Accuracy: 0.792135\n",
      "epoch: 809 - cost: 0.483573 -MSE: 30.8081907015 -Train Accuracy: 0.810393\n",
      "epoch: 810 - cost: 0.468757 -MSE: 30.1786894061 -Train Accuracy: 0.792135\n",
      "epoch: 811 - cost: 0.483181 -MSE: 30.80474711 -Train Accuracy: 0.811798\n",
      "epoch: 812 - cost: 0.468425 -MSE: 30.1767839138 -Train Accuracy: 0.792135\n",
      "epoch: 813 - cost: 0.482791 -MSE: 30.8012852654 -Train Accuracy: 0.811798\n",
      "epoch: 814 - cost: 0.468094 -MSE: 30.174865222 -Train Accuracy: 0.792135\n",
      "epoch: 815 - cost: 0.482403 -MSE: 30.7978100595 -Train Accuracy: 0.811798\n",
      "epoch: 816 - cost: 0.467765 -MSE: 30.1729272229 -Train Accuracy: 0.792135\n",
      "epoch: 817 - cost: 0.482016 -MSE: 30.7943200885 -Train Accuracy: 0.811798\n",
      "epoch: 818 - cost: 0.467437 -MSE: 30.170968417 -Train Accuracy: 0.792135\n",
      "epoch: 819 - cost: 0.481632 -MSE: 30.7908177651 -Train Accuracy: 0.811798\n",
      "epoch: 820 - cost: 0.467111 -MSE: 30.1689934734 -Train Accuracy: 0.792135\n",
      "epoch: 821 - cost: 0.481248 -MSE: 30.7872989555 -Train Accuracy: 0.811798\n",
      "epoch: 822 - cost: 0.466786 -MSE: 30.1669981676 -Train Accuracy: 0.792135\n",
      "epoch: 823 - cost: 0.480867 -MSE: 30.7837674419 -Train Accuracy: 0.811798\n",
      "epoch: 824 - cost: 0.466462 -MSE: 30.1649850622 -Train Accuracy: 0.792135\n",
      "epoch: 825 - cost: 0.480487 -MSE: 30.7802211316 -Train Accuracy: 0.811798\n",
      "epoch: 826 - cost: 0.46614 -MSE: 30.1629604255 -Train Accuracy: 0.792135\n",
      "epoch: 827 - cost: 0.480109 -MSE: 30.7766658591 -Train Accuracy: 0.813202\n",
      "epoch: 828 - cost: 0.465819 -MSE: 30.1609187153 -Train Accuracy: 0.792135\n",
      "epoch: 829 - cost: 0.479733 -MSE: 30.7731010536 -Train Accuracy: 0.813202\n",
      "epoch: 830 - cost: 0.4655 -MSE: 30.1588596787 -Train Accuracy: 0.793539\n",
      "epoch: 831 - cost: 0.479358 -MSE: 30.7695212847 -Train Accuracy: 0.813202\n",
      "epoch: 832 - cost: 0.465182 -MSE: 30.1567890711 -Train Accuracy: 0.793539\n",
      "epoch: 833 - cost: 0.478984 -MSE: 30.765931396 -Train Accuracy: 0.813202\n",
      "epoch: 834 - cost: 0.464866 -MSE: 30.1546983645 -Train Accuracy: 0.793539\n",
      "epoch: 835 - cost: 0.478613 -MSE: 30.7623307623 -Train Accuracy: 0.813202\n",
      "epoch: 836 - cost: 0.46455 -MSE: 30.1526023904 -Train Accuracy: 0.793539\n",
      "epoch: 837 - cost: 0.478243 -MSE: 30.7587249966 -Train Accuracy: 0.813202\n",
      "epoch: 838 - cost: 0.464237 -MSE: 30.1504861123 -Train Accuracy: 0.793539\n",
      "epoch: 839 - cost: 0.477875 -MSE: 30.7551021432 -Train Accuracy: 0.813202\n",
      "epoch: 840 - cost: 0.463924 -MSE: 30.1483614036 -Train Accuracy: 0.793539\n",
      "epoch: 841 - cost: 0.477508 -MSE: 30.751480065 -Train Accuracy: 0.813202\n",
      "epoch: 842 - cost: 0.463613 -MSE: 30.1462194774 -Train Accuracy: 0.793539\n",
      "epoch: 843 - cost: 0.477143 -MSE: 30.7478432955 -Train Accuracy: 0.813202\n",
      "epoch: 844 - cost: 0.463303 -MSE: 30.1440722808 -Train Accuracy: 0.793539\n",
      "epoch: 845 - cost: 0.476779 -MSE: 30.7442031835 -Train Accuracy: 0.813202\n",
      "epoch: 846 - cost: 0.462995 -MSE: 30.1419140037 -Train Accuracy: 0.793539\n",
      "epoch: 847 - cost: 0.476417 -MSE: 30.7405602356 -Train Accuracy: 0.813202\n",
      "epoch: 848 - cost: 0.462688 -MSE: 30.1397439792 -Train Accuracy: 0.793539\n",
      "epoch: 849 - cost: 0.476057 -MSE: 30.7369053593 -Train Accuracy: 0.813202\n",
      "epoch: 850 - cost: 0.462382 -MSE: 30.1375642306 -Train Accuracy: 0.793539\n",
      "epoch: 851 - cost: 0.475698 -MSE: 30.7332492829 -Train Accuracy: 0.813202\n",
      "epoch: 852 - cost: 0.462077 -MSE: 30.1353775372 -Train Accuracy: 0.793539\n",
      "epoch: 853 - cost: 0.475341 -MSE: 30.7295842112 -Train Accuracy: 0.813202\n",
      "epoch: 854 - cost: 0.461774 -MSE: 30.1331810828 -Train Accuracy: 0.793539\n",
      "epoch: 855 - cost: 0.474985 -MSE: 30.7259180896 -Train Accuracy: 0.811798\n",
      "epoch: 856 - cost: 0.461472 -MSE: 30.1309762903 -Train Accuracy: 0.793539\n",
      "epoch: 857 - cost: 0.47463 -MSE: 30.722246025 -Train Accuracy: 0.811798\n",
      "epoch: 858 - cost: 0.461171 -MSE: 30.1287642058 -Train Accuracy: 0.793539\n",
      "epoch: 859 - cost: 0.474278 -MSE: 30.7185761915 -Train Accuracy: 0.811798\n",
      "epoch: 860 - cost: 0.460872 -MSE: 30.1265497814 -Train Accuracy: 0.793539\n",
      "epoch: 861 - cost: 0.473927 -MSE: 30.714899294 -Train Accuracy: 0.811798\n",
      "epoch: 862 - cost: 0.460574 -MSE: 30.1243250259 -Train Accuracy: 0.794944\n",
      "epoch: 863 - cost: 0.473577 -MSE: 30.7112235453 -Train Accuracy: 0.811798\n",
      "epoch: 864 - cost: 0.460277 -MSE: 30.1220914446 -Train Accuracy: 0.794944\n",
      "epoch: 865 - cost: 0.473229 -MSE: 30.7075429361 -Train Accuracy: 0.811798\n",
      "epoch: 866 - cost: 0.459982 -MSE: 30.1198559414 -Train Accuracy: 0.794944\n",
      "epoch: 867 - cost: 0.472882 -MSE: 30.703861023 -Train Accuracy: 0.811798\n",
      "epoch: 868 - cost: 0.459687 -MSE: 30.1176147985 -Train Accuracy: 0.794944\n",
      "epoch: 869 - cost: 0.472537 -MSE: 30.7001794739 -Train Accuracy: 0.813202\n",
      "epoch: 870 - cost: 0.459394 -MSE: 30.1153727095 -Train Accuracy: 0.794944\n",
      "epoch: 871 - cost: 0.472194 -MSE: 30.6964998028 -Train Accuracy: 0.813202\n",
      "epoch: 872 - cost: 0.459102 -MSE: 30.113122584 -Train Accuracy: 0.794944\n",
      "epoch: 873 - cost: 0.471851 -MSE: 30.692816912 -Train Accuracy: 0.813202\n",
      "epoch: 874 - cost: 0.458812 -MSE: 30.1108694382 -Train Accuracy: 0.794944\n",
      "epoch: 875 - cost: 0.47151 -MSE: 30.6891378329 -Train Accuracy: 0.813202\n",
      "epoch: 876 - cost: 0.458522 -MSE: 30.1086187967 -Train Accuracy: 0.794944\n",
      "epoch: 877 - cost: 0.471171 -MSE: 30.6854579165 -Train Accuracy: 0.813202\n",
      "epoch: 878 - cost: 0.458234 -MSE: 30.1063619851 -Train Accuracy: 0.794944\n",
      "epoch: 879 - cost: 0.470833 -MSE: 30.6817804935 -Train Accuracy: 0.813202\n",
      "epoch: 880 - cost: 0.457947 -MSE: 30.1041017862 -Train Accuracy: 0.794944\n",
      "epoch: 881 - cost: 0.470496 -MSE: 30.6781043177 -Train Accuracy: 0.813202\n",
      "epoch: 882 - cost: 0.457661 -MSE: 30.1018469634 -Train Accuracy: 0.794944\n",
      "epoch: 883 - cost: 0.470161 -MSE: 30.6744340418 -Train Accuracy: 0.813202\n",
      "epoch: 884 - cost: 0.457377 -MSE: 30.0995888835 -Train Accuracy: 0.794944\n",
      "epoch: 885 - cost: 0.469828 -MSE: 30.6707690727 -Train Accuracy: 0.813202\n",
      "epoch: 886 - cost: 0.457094 -MSE: 30.0973303588 -Train Accuracy: 0.794944\n",
      "epoch: 887 - cost: 0.469495 -MSE: 30.6671034302 -Train Accuracy: 0.813202\n",
      "epoch: 888 - cost: 0.456811 -MSE: 30.0950677533 -Train Accuracy: 0.794944\n",
      "epoch: 889 - cost: 0.469164 -MSE: 30.663442255 -Train Accuracy: 0.813202\n",
      "epoch: 890 - cost: 0.456531 -MSE: 30.0928090965 -Train Accuracy: 0.794944\n",
      "epoch: 891 - cost: 0.468835 -MSE: 30.659786035 -Train Accuracy: 0.813202\n",
      "epoch: 892 - cost: 0.456251 -MSE: 30.0905498676 -Train Accuracy: 0.794944\n",
      "epoch: 893 - cost: 0.468507 -MSE: 30.6561364371 -Train Accuracy: 0.813202\n",
      "epoch: 894 - cost: 0.455972 -MSE: 30.0882967174 -Train Accuracy: 0.794944\n",
      "epoch: 895 - cost: 0.46818 -MSE: 30.6524934389 -Train Accuracy: 0.813202\n",
      "epoch: 896 - cost: 0.455695 -MSE: 30.0860413329 -Train Accuracy: 0.794944\n",
      "epoch: 897 - cost: 0.467855 -MSE: 30.6488539066 -Train Accuracy: 0.813202\n",
      "epoch: 898 - cost: 0.455418 -MSE: 30.0837922386 -Train Accuracy: 0.794944\n",
      "epoch: 899 - cost: 0.467531 -MSE: 30.6452189772 -Train Accuracy: 0.813202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 900 - cost: 0.455143 -MSE: 30.0815419682 -Train Accuracy: 0.794944\n",
      "epoch: 901 - cost: 0.467208 -MSE: 30.641590811 -Train Accuracy: 0.813202\n",
      "epoch: 902 - cost: 0.454869 -MSE: 30.0792947386 -Train Accuracy: 0.794944\n",
      "epoch: 903 - cost: 0.466886 -MSE: 30.6379695947 -Train Accuracy: 0.813202\n",
      "epoch: 904 - cost: 0.454596 -MSE: 30.0770472548 -Train Accuracy: 0.794944\n",
      "epoch: 905 - cost: 0.466566 -MSE: 30.6343535031 -Train Accuracy: 0.813202\n",
      "epoch: 906 - cost: 0.454324 -MSE: 30.0748051707 -Train Accuracy: 0.794944\n",
      "epoch: 907 - cost: 0.466247 -MSE: 30.6307458147 -Train Accuracy: 0.813202\n",
      "epoch: 908 - cost: 0.454053 -MSE: 30.0725729116 -Train Accuracy: 0.794944\n",
      "epoch: 909 - cost: 0.46593 -MSE: 30.6271491445 -Train Accuracy: 0.813202\n",
      "epoch: 910 - cost: 0.453783 -MSE: 30.0703402437 -Train Accuracy: 0.794944\n",
      "epoch: 911 - cost: 0.465614 -MSE: 30.6235611944 -Train Accuracy: 0.813202\n",
      "epoch: 912 - cost: 0.453515 -MSE: 30.0681134343 -Train Accuracy: 0.794944\n",
      "epoch: 913 - cost: 0.465299 -MSE: 30.6199792052 -Train Accuracy: 0.813202\n",
      "epoch: 914 - cost: 0.453247 -MSE: 30.065894064 -Train Accuracy: 0.794944\n",
      "epoch: 915 - cost: 0.464985 -MSE: 30.6164108275 -Train Accuracy: 0.813202\n",
      "epoch: 916 - cost: 0.452981 -MSE: 30.0636820835 -Train Accuracy: 0.794944\n",
      "epoch: 917 - cost: 0.464673 -MSE: 30.6128499645 -Train Accuracy: 0.813202\n",
      "epoch: 918 - cost: 0.452716 -MSE: 30.0614724329 -Train Accuracy: 0.794944\n",
      "epoch: 919 - cost: 0.464362 -MSE: 30.6093014948 -Train Accuracy: 0.816011\n",
      "epoch: 920 - cost: 0.452451 -MSE: 30.0592731386 -Train Accuracy: 0.794944\n",
      "epoch: 921 - cost: 0.464052 -MSE: 30.6057604596 -Train Accuracy: 0.816011\n",
      "epoch: 922 - cost: 0.452188 -MSE: 30.0570784476 -Train Accuracy: 0.794944\n",
      "epoch: 923 - cost: 0.463744 -MSE: 30.6022299294 -Train Accuracy: 0.817416\n",
      "epoch: 924 - cost: 0.451926 -MSE: 30.0548895073 -Train Accuracy: 0.794944\n",
      "epoch: 925 - cost: 0.463436 -MSE: 30.5987125668 -Train Accuracy: 0.817416\n",
      "epoch: 926 - cost: 0.451665 -MSE: 30.0527086053 -Train Accuracy: 0.794944\n",
      "epoch: 927 - cost: 0.463131 -MSE: 30.5952045152 -Train Accuracy: 0.817416\n",
      "epoch: 928 - cost: 0.451405 -MSE: 30.0505359298 -Train Accuracy: 0.794944\n",
      "epoch: 929 - cost: 0.462826 -MSE: 30.5917097473 -Train Accuracy: 0.817416\n",
      "epoch: 930 - cost: 0.451147 -MSE: 30.0483743407 -Train Accuracy: 0.794944\n",
      "epoch: 931 - cost: 0.462522 -MSE: 30.5882279778 -Train Accuracy: 0.817416\n",
      "epoch: 932 - cost: 0.450888 -MSE: 30.0462197301 -Train Accuracy: 0.797753\n",
      "epoch: 933 - cost: 0.46222 -MSE: 30.5847545768 -Train Accuracy: 0.817416\n",
      "epoch: 934 - cost: 0.450631 -MSE: 30.0440717475 -Train Accuracy: 0.797753\n",
      "epoch: 935 - cost: 0.461918 -MSE: 30.5812944579 -Train Accuracy: 0.817416\n",
      "epoch: 936 - cost: 0.450375 -MSE: 30.0419347974 -Train Accuracy: 0.797753\n",
      "epoch: 937 - cost: 0.461618 -MSE: 30.5778486912 -Train Accuracy: 0.817416\n",
      "epoch: 938 - cost: 0.45012 -MSE: 30.0398076739 -Train Accuracy: 0.797753\n",
      "epoch: 939 - cost: 0.461319 -MSE: 30.5744182767 -Train Accuracy: 0.817416\n",
      "epoch: 940 - cost: 0.449866 -MSE: 30.0376905286 -Train Accuracy: 0.797753\n",
      "epoch: 941 - cost: 0.461021 -MSE: 30.5709980084 -Train Accuracy: 0.81882\n",
      "epoch: 942 - cost: 0.449613 -MSE: 30.035584827 -Train Accuracy: 0.797753\n",
      "epoch: 943 - cost: 0.460724 -MSE: 30.5675920771 -Train Accuracy: 0.81882\n",
      "epoch: 944 - cost: 0.449361 -MSE: 30.0334876081 -Train Accuracy: 0.797753\n",
      "epoch: 945 - cost: 0.460429 -MSE: 30.5642023552 -Train Accuracy: 0.81882\n",
      "epoch: 946 - cost: 0.44911 -MSE: 30.0313996699 -Train Accuracy: 0.799157\n",
      "epoch: 947 - cost: 0.460135 -MSE: 30.5608239512 -Train Accuracy: 0.81882\n",
      "epoch: 948 - cost: 0.44886 -MSE: 30.0293204187 -Train Accuracy: 0.799157\n",
      "epoch: 949 - cost: 0.459842 -MSE: 30.5574580923 -Train Accuracy: 0.81882\n",
      "epoch: 950 - cost: 0.448611 -MSE: 30.0272517654 -Train Accuracy: 0.799157\n",
      "epoch: 951 - cost: 0.45955 -MSE: 30.5541065064 -Train Accuracy: 0.81882\n",
      "epoch: 952 - cost: 0.448363 -MSE: 30.0251937678 -Train Accuracy: 0.799157\n",
      "epoch: 953 - cost: 0.459259 -MSE: 30.5507706036 -Train Accuracy: 0.81882\n",
      "epoch: 954 - cost: 0.448116 -MSE: 30.0231510031 -Train Accuracy: 0.800562\n",
      "epoch: 955 - cost: 0.458969 -MSE: 30.5474513075 -Train Accuracy: 0.81882\n",
      "epoch: 956 - cost: 0.44787 -MSE: 30.0211149372 -Train Accuracy: 0.800562\n",
      "epoch: 957 - cost: 0.458681 -MSE: 30.5441490317 -Train Accuracy: 0.81882\n",
      "epoch: 958 - cost: 0.447625 -MSE: 30.019097828 -Train Accuracy: 0.800562\n",
      "epoch: 959 - cost: 0.458393 -MSE: 30.5408612668 -Train Accuracy: 0.81882\n",
      "epoch: 960 - cost: 0.447381 -MSE: 30.017086835 -Train Accuracy: 0.800562\n",
      "epoch: 961 - cost: 0.458107 -MSE: 30.5375840455 -Train Accuracy: 0.81882\n",
      "epoch: 962 - cost: 0.447138 -MSE: 30.0150879079 -Train Accuracy: 0.800562\n",
      "epoch: 963 - cost: 0.457821 -MSE: 30.5343271236 -Train Accuracy: 0.81882\n",
      "epoch: 964 - cost: 0.446895 -MSE: 30.0131032172 -Train Accuracy: 0.803371\n",
      "epoch: 965 - cost: 0.457537 -MSE: 30.5310826607 -Train Accuracy: 0.81882\n",
      "epoch: 966 - cost: 0.446654 -MSE: 30.0111286574 -Train Accuracy: 0.801966\n",
      "epoch: 967 - cost: 0.457254 -MSE: 30.5278598714 -Train Accuracy: 0.81882\n",
      "epoch: 968 - cost: 0.446413 -MSE: 30.0091688704 -Train Accuracy: 0.801966\n",
      "epoch: 969 - cost: 0.456972 -MSE: 30.5246494085 -Train Accuracy: 0.81882\n",
      "epoch: 970 - cost: 0.446174 -MSE: 30.0072214433 -Train Accuracy: 0.801966\n",
      "epoch: 971 - cost: 0.456691 -MSE: 30.5214545147 -Train Accuracy: 0.816011\n",
      "epoch: 972 - cost: 0.445935 -MSE: 30.005279674 -Train Accuracy: 0.801966\n",
      "epoch: 973 - cost: 0.456411 -MSE: 30.5182795388 -Train Accuracy: 0.816011\n",
      "epoch: 974 - cost: 0.445697 -MSE: 30.0033594248 -Train Accuracy: 0.801966\n",
      "epoch: 975 - cost: 0.456132 -MSE: 30.5151179989 -Train Accuracy: 0.816011\n",
      "epoch: 976 - cost: 0.44546 -MSE: 30.0014498782 -Train Accuracy: 0.801966\n",
      "epoch: 977 - cost: 0.455855 -MSE: 30.5119748729 -Train Accuracy: 0.816011\n",
      "epoch: 978 - cost: 0.445224 -MSE: 29.9995559013 -Train Accuracy: 0.801966\n",
      "epoch: 979 - cost: 0.455578 -MSE: 30.5088481341 -Train Accuracy: 0.816011\n",
      "epoch: 980 - cost: 0.444989 -MSE: 29.9976745744 -Train Accuracy: 0.801966\n",
      "epoch: 981 - cost: 0.455302 -MSE: 30.5057414727 -Train Accuracy: 0.816011\n",
      "epoch: 982 - cost: 0.444755 -MSE: 29.9958071166 -Train Accuracy: 0.801966\n",
      "epoch: 983 - cost: 0.455027 -MSE: 30.5026484406 -Train Accuracy: 0.816011\n",
      "epoch: 984 - cost: 0.444522 -MSE: 29.9939506582 -Train Accuracy: 0.801966\n",
      "epoch: 985 - cost: 0.454754 -MSE: 30.4995710836 -Train Accuracy: 0.816011\n",
      "epoch: 986 - cost: 0.444289 -MSE: 29.9921087657 -Train Accuracy: 0.801966\n",
      "epoch: 987 - cost: 0.454481 -MSE: 30.4965160816 -Train Accuracy: 0.816011\n",
      "epoch: 988 - cost: 0.444057 -MSE: 29.9902822921 -Train Accuracy: 0.801966\n",
      "epoch: 989 - cost: 0.454209 -MSE: 30.4934760673 -Train Accuracy: 0.817416\n",
      "epoch: 990 - cost: 0.443827 -MSE: 29.9884677987 -Train Accuracy: 0.801966\n",
      "epoch: 991 - cost: 0.453939 -MSE: 30.4904542755 -Train Accuracy: 0.817416\n",
      "epoch: 992 - cost: 0.443597 -MSE: 29.9866732161 -Train Accuracy: 0.801966\n",
      "epoch: 993 - cost: 0.453669 -MSE: 30.4874514272 -Train Accuracy: 0.817416\n",
      "epoch: 994 - cost: 0.443368 -MSE: 29.9848902882 -Train Accuracy: 0.801966\n",
      "epoch: 995 - cost: 0.4534 -MSE: 30.4844694503 -Train Accuracy: 0.817416\n",
      "epoch: 996 - cost: 0.443139 -MSE: 29.9831225622 -Train Accuracy: 0.801966\n",
      "epoch: 997 - cost: 0.453133 -MSE: 30.4815042373 -Train Accuracy: 0.817416\n",
      "epoch: 998 - cost: 0.442912 -MSE: 29.9813682737 -Train Accuracy: 0.801966\n",
      "epoch: 999 - cost: 0.452866 -MSE: 30.4785562176 -Train Accuracy: 0.817416\n",
      "Model saved in file: C:\\Users\\ayana\\Documents\\ML\\Machine Learning With Python\\model.h5\n"
     ]
    }
   ],
   "source": [
    "mse_history=[]\n",
    "accuracy_history=[]\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n",
    "    cost=sess.run(cost_function,feed_dict={x:train_x,y_:train_y})\n",
    "    cost_history=np.append(cost_history,cost)\n",
    "    correct_prediction=tf.equal(tf.argmax(Y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    #print accuracy\n",
    "    \n",
    "    pred_y=sess.run(Y,feed_dict={x:test_x})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "    \n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=(sess.run(accuracy,feed_dict={x:train_x,y_:train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,\"-MSE:\",mse_,\"-Train Accuracy:\",accuracy)\n",
    "    \n",
    "save_path=saver.save(sess,model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nckKBLiKSEwp0EZGcUKCLiOTE/wMrDllJiReC/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195e0fd0160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mse and accuracy graph\n",
    "plt.plot(mse_history,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPr/QnuAA/B+J00AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x195d4adfeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.782123\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(Y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy:\",(sess.run(accuracy,feed_dict={x:test_x,y_:test_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print the final mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:30.4786\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(Y,feed_dict={x:test_x})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-test_y))\n",
    "print(\"MSE:%.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.argmax(Y,1)\n",
    "correct_prediction=tf.equal(prediction,tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print accuracy run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "0 stands for Not Survived  and 1 stands for Survived\n",
      "******************************\n",
      "393 Original Class:  0  Predicted Values:  1\n",
      "Accuracy:  0.0%\n",
      "394 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "395 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "396 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "397 Original Class:  1  Predicted Values:  1\n",
      "Accuracy:  100.0%\n",
      "398 Original Class:  1  Predicted Values:  0\n",
      "Accuracy:  0.0%\n",
      "399 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n",
      "400 Original Class:  0  Predicted Values:  0\n",
      "Accuracy:  100.0%\n"
     ]
    }
   ],
   "source": [
    "print('******************************')\n",
    "print(\"0 stands for Not Survived  and 1 stands for Survived\")\n",
    "print('******************************')\n",
    "\n",
    "for i in range(393,401):\n",
    "    \n",
    "    prediction_run = sess.run(prediction, feed_dict={x:X[i].reshape(1,7)})\n",
    "    accuracy_run = sess.run(accuracy, feed_dict={x:X[i].reshape(1,7), y_:y[i].reshape(1,2)})\n",
    "    print(i,\"Original Class: \", int(sess.run(y_[i][1],feed_dict={y_:y})), \" Predicted Values: \", prediction_run[0] )\n",
    "    print(\"Accuracy: \",str(accuracy_run*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
